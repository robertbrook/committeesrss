"&#xa0;\nWritten evidence submitted by ISPA [OLS089]&#xa0;\n&#xa0;Introduction&#xa0;\nThe Internet Services Provider's Association is the trade association for the internet industry in the UK. ISPA has over 200 members from across the sector, including a large number of access provider ISPs from small to large, content platforms, hosting providers and others. ISPA therefore works across the areas in which the Committee is looking and we welcome the opportunity to provide input into the Committee's inquiry.\n&#xa0;\nWe believe that the Committee's terms of reference for the inquiry identify the key issues that are currently of relevance in relation to online safety. However, we would like to emphasise that the issues that have been identified should not be conflated. The issue of tackling child abuse content, which is clearly illegal, requires a different response from industry and Government than the availability of extremist material which may or may not be illegal. Protecting children from accessing potentially harmful content again requires a different response as it may cover content that is clearly legal but simply not appropriate for children and young people under 18.\n&#xa0;\nWe further welcome that the Committee considers that any potential dangers of the internet are a \"correlation of the immense benefits provided by unimpeded communication and free speech\" and that \"any attempts to mitigate harms have to be proportionate and, where possible, avoid disadvantageous consequences.\" We believe that the recognition of this correlation is of vital importance but are concerned that policy-makers sometimes disregard it which often leads to disconnected and potentially harmful policy-making.\n&#xa0;Variety of Internet companies&#xa0;\nIt is important that the Committee understands that there is a considerable diversity of companies that operate internet services. When considering the steps that industry can take, it is important to consider that each type of company may be playing a different role, and they will have varying degrees of ability to deal with potentially illegal or harmful content. The below description provides a rough guide\n to the various kinds of companies that are involved in making the Internet work. If it were felt to be helpful, we would be happy to brief the Committee in more detail about the position of each company type in the internet value chain.\n&#xa0;\nAccess providers&#xa0;\nAccess providers are commonly referred to as Internet Service Providers. They connect customers to the Internet—either through fixed or wireless connectivity. As the ISP does not initiate or modify their users' communications and is only passing traffic across a network, they are deemed \"mere conduits\" under the E-Commerce Regulation 17 which grants limited liability.\n&#xa0;\nHosting providers&#xa0;\nHosting providers store others' content online, often for a charge. Traditionally hosting providers have hosted complete websites of individuals and companies and even Government hosts some of its websites with these private hosting providers.\n&#xa0;\nMore recently, new types of hosting provider have emerged. These providers, e.g. social networks, generally provide a platform on which users can upload content (videos, blog posts, \nimages etc.) which they themselves have created. These kinds of hosting provider do not have editorial control over what is posted on their services, but may have active or passive moderating policies that allow them to remove content or restrict its availability.\n&#xa0;\nUnder Regulation 19 of the e-Commerce Regulations both traditional and modern hosting providers are not considered to be liable for the content they host as long as they do not have actual knowledge of unlawful activity or information. However, upon obtaining such knowledge, hosting providers become liable if they do not act expeditiously to remove or to disable access to\nthe\n information.\n&#xa0;\nWebsites where operators have editorial control&#xa0;\nIndividuals, companies and other organisations that run their own websites can be regarded as having editorial control over content that is available via their website and so are considered to have more direct responsibility. However, it is important to point out that websites can contain \nboth content\n where the operator of a website has editorial control, e.g. a news article, and user generated content, e.g. comments about that news article.\n&#xa0;\nSearch engines&#xa0;\nSearch engines index web pages by scanning the Internet. They use algorithms to display relevant results based on what search terms users input but generally do not exercise editorial control over the links that they present to users. Search engines can be considered as \"caches\" under Regulation 18 of the e-Commerce Regulations and act expeditiously to remove or to disable access to any information if they are made aware of that the fact that this information may be illegal.\n&#xa0;\nHow does this apply in the real world?&#xa0;\nIt is worth considering three different examples:\n&#xa0;\n1. A website hosting child abuse images\n2. A person who posts a potentially illegal message on a website operated by the same person\n3. A person who posts a potentially illegal message on a forum operated by a third party\n&#xa0;\nIn relation to the first example, ideally the hosting \nproviders who provides\n the space for the website should be notified that illegal material is being hosted on a website on one of its servers. This notification is being done on a regular and effective basis by the IWF. If the operator is based outside of the UK and responds slowly or not at all to a notice from the IWF or its international partners, the IWF can add this page to its list of illegal websites. Access providers accept the judgment of the IWF, which has great expertise in this area, and use the IWF's list to filter out the relevant page (i.e. they make the URL of that website inaccessible, and a user would see an error message if they attempted to access it).\n&#xa0;\nIn relation to the second, the person should be approached directly as they have editorial control of the comment and the website on which it can be found. If the person does not respond then it may be necessary to contact the hosting provider who provides the space for the website who may then need to make an expeditious assessment of the content and take it down if appropriate. The access provider would theoretically be able to block access to the \nwebsite but this would be less timely and cost efficient than approaching the hosting provider and generally requires a valid takedown notice.\n&#xa0;\nIn relation to the final example, again, the person who posted the content should be approached directly. However, if the person does not respond, or cannot be identified, the third party who operates the forum should be approached who will then need to make an expeditious assessment of the content and take it down if appropriate. If the third party does not react then it may be necessary to approach the hosting provider, however, this should be a matter of last resort as the provider would generally only be able to remove the whole forum, thereby curtailing the service and rights other forum users. The same would be true if an access provider would block access to the forum.\n&#xa0;\nIn all these examples it is important to note that it is often not clear cut whether content is illegal or not and online companies cannot be expected to be the judge and jury of others' content.\n&#xa0;Industry has a role to play&#xa0;We strongly believe that the industry has a vital role to play in protecting minors from accessing inappropriate content and would like to emphasise that the UK is widely regarded as having one of the most advanced online safety frameworks.\n&#xa0;\nFamily friendly filters&#xa0;&#xa0;\nChild sexual abuse content&#xa0;&#xa0;\nAllegedly/potentially illegal content&#xa0;\n&#xa0;\n&#xa0;\n&#xa0;\nIndustry cannot solve these issues on its own&#xa0;\nHowever, we are concerned that the current policy debate is sometime too strongly focused on finding a technological fix to a problem that often has societal roots and is sometimes present in both the offline and online world.\n&#xa0;\nFor example, in the relation to the accessibility of adult content, we accept that ISPs should play a role in empowering their customers to better determine what content should be available in their household. However, even the most comprehensive filtering solution cannot guarantee that adult content will be unavailable. Over and \nunderblocking\n of content is inevitable and it is important that filtering tools are viewed as part of a wider package alongside education and parental mediation. There needs to be more emphasis on enabling parents and teachers to teach children how to behave responsibly online, one possible action could be the updating of sex education in the curriculum so that it keeps pace with technological and societal developments.\n&#xa0;\nIn relation to abusive or threatening comments online, we would like to emphasise that ISPs should not be used as proxy for enforcing the law and perceived societal standards. Social media networks can and often take action against users that behave inappropriately. However it has to be taken into account that the Crown Prosecution Service's Guidelines on prosecuting cases involving communications sent via social media state that “[j]\nust\n because the content expressed in the communication is in bad taste, controversial or unpopular, and may cause offence to individuals or a specific community, this is not in itself sufficient reason to engage the criminal law.\" This should not be regarded as a get out clause for providers but it is important to point out that providers cannot be expected to go beyond what is required by the law. In this context, it worth highlighting that Parliament has recently amended the Defamation Act which encourages hosting providers to assist the resolution of disputes between users that cannot be resolved by the hosting provider themselves\n&#xa0;Conclusion&#xa0;\nWe have shown that industry has made available a number of tools, services and advice to help protect minors from accessing adult content. There is cooperation between industry and law enforcement to tackle extremist material when legal thresholds are crossed. Websites have in place mechanisms to prevent abusive behaviour and the law had been used to prosecute individuals in some instances.\n&#xa0;\nThe Internet has had a significant impact on modern societies. It has changed how we do business, communicate, educate and consume content. These changes came about because internet companies developed innovative products and consumers have found even more innovative and sometime unexpected ways of using these products. As such the Internet is an extension of the established offline world and it would be wrong to simply ask ISPs to fix any issues that may arise.\n&#xa0;\nTechnological fixes can play a role and support customers but we will only be able to comprehensively tackle the problems that the Committee outlined in its terms of reference by involving industry, Government, parents and users and by looking at both the symptoms and causes. The Internet industry has reviewed and improved its offering to customers in recent times. It is willing to actively engage with the online safety agenda but we hope that this can be done in a more positive environment based on collaboration.\n&#xa0;\nOctober 2013\n&#xa0;\n \nWe merely consider the e-Commerce Regulations and online companies may have duties and defences through other legislation.\n \nRegulation 18 defines providers as \n\"ca\nc\nhes\" if\n the information that is processed by them is \"the subject of automatic, intermediate\nand temporary storage where that storage is for the sole purpose of making more efficient onward transmission of the information to\nother\n recipients of the service upon their request\", \ni.e\n, the provider merely processes information and only stores it temporarily.\n \nHL Deb, 23 September 2013\n,c421W\n.\n"