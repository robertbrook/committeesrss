&#xa0;
[normal]Our evidence raises four points:
[normal]Full Fact is an independent 
[normal]factchecking
[normal] organisation. We provide 
[normal]free tools, advice and information so anyone can check the claims we hear from politicians and the media.
[normal] We are frequent users of open data and official statistics and often assist others who are trying to use them.
[normal]&#xa0;
[normal]Open data is a 
[normal]great
[normal] thing of which we have seen too little, too late, too poorly done. Because it has been poorly done the take up has been limited. The government’s agenda of open by default and Tim Berners-Lee’s definition of five star open data taken up in the open data white paper now set the right ambition for open data generally—they are both inspirations and basic necessities.
[normal]Yet these two fundamentals of the open data agenda sail irrelevantly past the world of official statistics. Open by default is already one of the most fundamental principles of trustworthy official statistics.
[normal] Meanwhile, the definition of five star open data explicitly omits any requirement about metadata, so hardly applies to statistics.
[normal]A statistic isn’t a number on its own. It’s the number plus the explanation of where it comes from, how it’s generated, how that has changed over time, the caveats, definitions and what it can and can’t be compared to. Openness about all this context is a big part of what makes official statistics trustworthy. The Committee illustrated that powerfully in a recent report: what’s the use of knowing the net migration figure without knowing that it’s only accurate to +/- 34,000? Or having an opinion survey without knowing the sample size? Or a headline measure of crime without knowing it doesn’t include murder? Open metadata, and context, and intelligent explanation, are inseparable parts of open statistics.
[normal]If we blindly apply the broader work of open data to the particular challenge of making official statistics open we risk becoming a country that knows the format of everything and the meaning of nothing.
[normal]Much open data is not statistics and doesn’t need the level of context we take for granted from official statistics. None of this therefore is to decry the many important achievements of the open 
[normal]data process so far, or the achievements to come. However, in order to exploit the ideas and principles behind open data in the context of official statistics, we need to raise our sights again.
[normal]&#xa0;
[normal]Official statistics should be open data and more than open data. With the capabilities of our expert official statisticians behind them, they should lead the field. As yet, they do not.
[normal]Statisticians should not be gatekeepers who determine what statistics we can see and what we can do with them. They must be enablers, priding themselves on openness and how their work, including as the Committee has emphasised, their communication work, empowers others to do whatever it is they want to do. There are of course specific exceptions, such as limited access to low level statistics on infections which may disclose sensitive personal information. 
[normal]This does not mean there needs to be a rush to publish whatever we can in whatever format we can. As the Committee has reminded us in previous studies in this series high-quality presentation is vital to presenting statistics. 
[normal]Open statistics should allow:
[normal]Machine readable open statistics could power a new generation of tools that improve the presentation of official statistics and their understanding by policy makers and the public. 
[normal]They will also help to prepare the ground for much more sophisticated government use through data matching combinations of existing datasets, which can be an extremely cumbersome task.
[normal]Here we outline a 1 star to 5 star scheme for assessing the reusability of open statistics, building on Tim Berners-Lee’s scheme for assessing the reusability of open data generally, as laid out in the white paper. It is intended for application to official statistics data/spreadsheets, not to the wider set of bulletins, 
[normal]infographics
[normal], videos etc. that may be part of a statistical release.
[normal]&#xa0;
[normal](0 – 
[normal]              
[normal]Published, with tabular data provided as spreadsheets. Although this is equivalent to 2* open data, in statistics it is a bare minimum. Statistics not published in this way would usually be in breach of the Code.)
[normal]1* – 
[normal]              
[normal]Basic metadata included. For example, the geographic scope of statistics (e.g. UK 
[normal]vs
[normal] England and Wales) and whether or not financial time series are inflation-adjusted. 
[normal]2* – 
[normal]              
[normal]The above, made available at a consistent URL (web address) with a consistent title or identifier and open machine readable standards used for data
[normal] 
[normal]where applicable.
[normal]3* – 
[normal]              
[normal]All of the above, but include explanation and caveats.
[normal]4* – 
[normal]              
[normal]All of the above, but in addition to using open formats, use URLs to identify things using open standards and w3c recommendations so that other people can point at the data.
[normal]5* – 
[normal]              
[normal]All of the above, but in addition to using open formats and URLs to identify things, link your data to other people’s data to provide context.
[normal]&#xa0;
[normal]These star levels are drawn from our positive and negative experiences of trying to reuse a very wide range of official and unofficial statistical datasets, which is part of our daily work. If adopted, they would make a considerable practical difference for users. They reflect existing best practice and would, we hope, be a useful tool for promoting good practice more widely. They could perhaps be incorporated into assessments for national statistics status as a way of driving that improvement.
[normal]For example, 1* reflects the time we and surely many other users have wasted trying to find answers to such basic questions as whether a series of financial numbers is inflation-adjusted. Other examples might include sample sizes, confidence intervals and seasonal adjustment where applicable.
[normal]2* refers to machine readable standards that can be unambiguously interpreted by computers, such as the ISO 8601 date format as promulgated by w3c (YYYY-MM-DD), ISO 3166 country codes, or ONS geographic codes to identify areas within the UK. Anyone who has done local authority level mapping of statistics will recognise the pain of having one local authority referred to by three subtly different names (‘Bristol, City of’, ‘City of Bristol’, ‘Bristol’). Providing its ONS geographic code avoids this problem. Existing ONS guidance already recommends “
[normal]that the appropriate area codes are presented when disseminating tables electronically
[normal].”
[normal]3* reflects basic good practice of ensuring important caveats and methodological notes are provided and highlighted to users. For example, crime figures, which are notoriously bedevilled by definitional changes, list major changes in methodology as well as anomalies such as a large increase in blackmail in 2006/07 “
[normal]due to the recording of threats made against shareholders of GlaxoSmithKline by animal rights activists.
[normal]”
[normal]4* and 5* reflect the opportunities to take all of these points and relate them as Tim Berners-Lee did to the opportunities of the open semantic web.
[normal]&#xa0;
[normal]Full Fact has done extensive work mapping out a path toward more usable and reusable open statistics. This includes developing prototype formats for presenting statistical data and applications to make use of it. We have presented some of this work at Government Statistical Service events and received interest from a number of departments and public bodies. This long-standing programme of work and our extensive experience as users of official statistics give us confidence that the scheme set out above is both practical and one that would produce significant benefits, 
[normal]including offering some quick wins of the sort that the open data agenda around statistics has perhaps been lacking.
[normal]&#xa0;
[normal]‘Data is the pollution of the information age’. It is a by-product of every action we take: until recently even walking past a bin in London has been enough to generate records.
[normal] On the other hand, privacy has long been one of the most contentious areas for trust in official statistics: the census, migration, and NHS computer systems are prominent examples. 
[normal]We will soon have far greater volumes of far more personal information stored by public bodies than we would have thought possible not long ago. Open data will serve as a constant reminder of this and occasional mistakes will bring it crashing into public debate. Both who knows what about me personally and what the government can learn or infer about individuals or society from aggregate data are likely to become debates that threaten trust in public administration in general and official statistics in particular.
[normal]It is likely that even when what the government is doing is far less than what private companies are doing, concern and distrust will be higher. When the government goes beyond that, exploiting the kinds of records that only it can access, it must be prepared for the ensuing public debate.
[normal]We submit these concerns to the Committee for its consideration. It seems sensible that careful thought should be given both to safeguards and to convincing all of us who are subjects of the data being collected of the strength of those safeguards. In particular, every effort should be made to avoid the appearance that data is just dumped online because people need and deserve to know that their data is treated with care. The practice of official statistics including statements of standards which let users know for example whether or not they have been independently assessed as meeting the Code of Practice might be a useful model.
[normal]There might be some role for the UK Statistics Authority in securing these standards or alternatively some risk that the fuzzy boundary between relatively 
[normal]unpoliced
[normal] ‘data’ and code-compliant ‘statistics’ serves to undermine its role. Either way, we believe the problem of trust is one that deserves the Committee’s attention.
[normal]&#xa0;
[normal]September 2013
[normal]&#xa0;
[normal] It’s not always lived up to, for example with ad hoc statistics.
[normal] 
[normal]http://www.ons.gov.uk/ons/guide-method/geography/geographic-policy/best-practice-guidance/presentation-order-guidance/index.html
[normal] 
[normal]http://www.ons.gov.uk/ons/rel/crime-stats/crime-statistics/period-ending-march-2013/rft---appendix-tables.xls
[normal] 
[normal]http://www.cityoflondon.gov.uk/about-the-city/what-we-do/media-centre/news-releases/2013/Pages/city-orders-waste-bin-data-collection-to-stop.aspx
[normal]