"&#xa0;\nWritten evidence submitted by Dr Clair Hardaker [OLS 0006]&#xa0;\nIn this document I discuss the following four points:\n(1)\n&#xa0;&#xa0;&#xa0;&#xa0; \nWhilst my research has covered strategies of content filtering, it relates better to the discussion of \"preventing abusive or threatening comments\", and less directly to \"protecting minors from adult content\" or \"filtering extremist material such as child abuse imagery\". I therefore do not comment on these two areas.\n(2)\n&#xa0;&#xa0;&#xa0;&#xa0; \nA crucial point note, however, is that \nfiltering\n content intended to promote harmful behaviour (e.g. terrorism, violence) is unlikely to deal with the online grooming responsible for inciting these behaviours. Grooming is typically an interactive process involving a manipulator persuading a vulnerable target to undertake action that is in the manipulator's interest, and typically harmful to the target (e.g. extremist violence, suicide, self-harm, age-inappropriate sexual behaviour, etc.).\n(3)\n&#xa0;&#xa0;&#xa0;&#xa0; \nSuch grooming is likely to occur in interactive environments such as \nchatrooms\n, \nmessageboards\n, and via private direct-message software (e.g. Windows Live Messenger) where content filtering will struggle to apply, and where processes of moderation are likely to be far more effective. I would therefore suggest that content filtering as a strategy for dealing with material intended to promote terrorism or other acts of violence is unlikely to tackle this point with much success.\n(4)\n&#xa0;&#xa0;&#xa0;&#xa0; \nThere are arguably three major factors (though easily more besides):\n(5)\n&#xa0;&#xa0;&#xa0;&#xa0; \nThe internet offers a perceived anonymity that has no real parallel offline, and this appearance of invisibility encourages the user to feel that they can do unpleasant things with a highly reduced risk of suffering any consequences. In turn, the sense of being invulnerable encourages \ndisinhibition\n: the user thinks that she is safe from repercussions, so behaves in a mildly objectionable way. Each time there is no negative consequence, her behaviour may gradually escalate.\n(6)\n&#xa0;&#xa0;&#xa0;&#xa0; \nBy itself, however, anonymity does not explain why the internet seems to bring the worst out in some, since many of us are online and anonymous all the time, yet would never think to behave in this way. A second issue to consider, then, is detachment.\n(7)\n&#xa0;&#xa0;&#xa0;&#xa0; \nLinked to \ndisinhibition\n is the way that the internet allows us to shut down our empathy, and in particular, our compassion. In fact, we can choose not to empathise at will, especially when dealing with someone we dislike. The internet, however, drastically increases this ability, and allows us to emotionally distance ourselves—not just from people we don't like but also from those we don't even know—in several ways:\n(a)\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nDehumanising\n: Because we lose many indications of emotional response (eye contact, tone of voice, facial expressions) it is easier to \"forget\" that we are communicating with another human. Instead, we have only the words and/or images sent back and forth.\n(b)\n&#xa0;&#xa0;&#xa0;&#xa0; \nDevaluing\n: The above means that we can downplay any emotional reaction. If they claim to be offended or hurt, because we don't see that reaction, it is easier to believe that they are lying or exaggerating. It is also easier to quickly forget the incident, whilst it may linger in the other's mind for days.\n(c)\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nVictim-blaming\n: It can be easier for the bully/troll to shift the responsibility for what they are doing from themselves, and blame their victim for what is happening, because, e.g., they're famous, or they made a tribute page public, etc.. This stance is typically also indicated by \"solutions\" such as telling the victim that if they don't like it, they should \"get off the internet\".\n(d)\n&#xa0;&#xa0;&#xa0;&#xa0; \nSelf-vindicating\n: It can also easier to diminish the severity of our behaviour to ourselves. Because we each inhabit our own heads, it seems obvious to us just how seriously we meant something, so when trolls/\ncyberbullies\n are confronted, we tend to hear excuses like, \"Stuff said on the internet isn't real. I was just joking. I obviously didn't really mean that [rape-threat/defamatory statement/etc.].\" Our innate bias means that we are more likely to adopt such a self-supporting viewpoint than to judge our own behaviour as reprehensible.\n(8)\n&#xa0;&#xa0;&#xa0;&#xa0; \nThe third aspect that seems to encourage some to be deliberately mean online long predates the internet. It is simply the human tendency to enjoy and glorify aggression. Evidence for this can be found worldwide, stretching back over millennia. For brevity, however, we need only look at ancient military artefacts (e.g. the Bayeux tapestry, Homer's \nIliad\n, \nBeowulf\n), the sports descended directly from warfare (javelin, archery, fencing, boxing, wrestling, martial arts), and archaeology built especially for the enjoyment of bloodshed (e.g. the Coliseum, the Hippodrome).\n(9)\n&#xa0;&#xa0;&#xa0;&#xa0; \nToday, one glance at mainstream entertainment demonstrates that this interest is not remotely abated. For instance, \nThe Hunger Games\n is a book series about individuals forced to fight to the death for a reality television show. \nShawshank\n Redemption\n tells of a man wrongly convicted for the murder of his wife and incarcerated in a brutal, corrupt prison where inmates are beaten to death, shot, and raped. \nThe X Factor\n television series places competitors into highly stressful, even cruel environments with antagonistic judges. And many of the biggest games titles, such as the \nCall of Duty\n, \nHalo\n, and \nGrand Theft Auto\n series, involve players simulating extreme violence and murder.\n(10)\n&#xa0;&#xa0; \nThe above should demonstrate that humans are entertained by violence, and that this is by no means a new phenomenon brought about by digital media. For some, however, simply consuming aggression-based entertainment from fiction (e.g. books, films) or simulation (e.g. games, sports) is not enough. For them, the internet presents a virtual Coliseum where they can amuse themselves by attacking others without risk of \"injury\", since they can hide behind a cloak of anonymity, and silence their own conscience by ignoring their target's feelings.\n(11)\n&#xa0;&#xa0; \nTo reiterate a point from above, whilst many of us are frequently online anonymously \nand\n enjoy consuming violence (it is a rare person who hasn't watched an action movie!), it is still a relatively small number who feel motivated to take advantage of the conditions that the internet presents, and to actually engage in abusive or threatening online behaviour. In the same way, many of us drive, but however annoyed we may become behind the wheel, mercifully few of us are ever turn our car into a lethal weapon.\n(12)\n&#xa0;&#xa0; \nIn other words, each individual needs a trigger, or motive to push them into using the internet as a weapon. Unsurprisingly, the evidence suggests that there is no single, over-riding motive for being abusive or threatening online, but that whilst there certainly are \ntrends,\n there are also many unique cases. Some of those broad trends include:\n(a)\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nBoredom, a need for entertainment\n: This is perhaps the most trivial reason (and therefore, perhaps also the most frustrating and difficult to resolve)—simply too much free time after \nschool, at work, or between jobs. These are the individuals who are killing time, and even seeking impress others of a similar mindset. Groups of trolls coalesce on sites like 4chan, post links to targets that might prove \"fun\", and compete against each other to see who can be the funniest, cleverest, or most extreme. They may also organise troll raids via more secure systems (e.g. \nIRC\n, \nTorchat\n), and train newer recruits in how to be less identifiable online, e.g. by sharing information about identity-protecting software such as \nTOR\n, \nI2P\n, and \nPsiphon\n.\n(b)\n&#xa0;&#xa0;&#xa0;&#xa0; \nA need for attention\n: these individuals seem to display a craving for any kind of attention, whether positive or negative. Such individuals may also post annoyingly implausible stories, grand claims, age-inappropriate content, etc\n..\n This may be symptomatic of emotional, social, and/or psychological problems.\n(c)\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nRevenge, disenfranchisement\n: these appear to be individuals who feel cheated, short-changed, or otherwise wronged on a personal level, and appear to want to \"fix\" this by making the object of their malice feel as miserable as \nthemselves\n. This may be symptomatic of a struggling economy, e.g. the student who can't find work and has therefore taken to targeting his local MP.\n(d)\n&#xa0;&#xa0;&#xa0;&#xa0; \nPolitics, activism\n: whilst the motive in its own right may be good (e.g. fighting for racial equality) the method may not meet that same moral standard. This said\n,\n it's easier to comprehend why individuals might choose this noisy, attention-grabbing route if we consider that letters to politicians, newspapers, and economists are all too easily ignored. This may be symptomatic, therefore, of a political system that appears (to the trolls/bullies) to ignore their voices.\n(13)\n&#xa0;&#xa0; \nIn summary, motivations for posting abusive/threatening content can spring from a number, and a mixture of sources, including emotional, psychological, social, political, economical, etc\n..\n This means that there is likely to be no \nsingle\n approach that will have any meaningful impact on this issue. Instead, it is far more likely to require addressing on multiple fronts. I discuss this area next.\n(14)\n&#xa0;&#xa0; \nThere are two classic \"solutions\" that have been proposed to fix online abusive comments. I deal with them briefly since they merit very little serious consideration.\n(15)\n&#xa0;&#xa0; \nIn a nutshell, this is borderline impossible, if only because it is unenforceable, and unworkable. Even if all countries agree to legally mandating online identity disclosure (unlikely) the costs of setting up, administrating, and then enforcing it would be staggering. Further, we need only consider the risks inherent in having a child's name, age, location, etc. available online to realise that online identity disclosure would actually create more dangers than anonymity currently averts.\n(16)\n&#xa0;&#xa0; \nThis is not only bizarrely unrealistic, since the internet is now \nubiquitous,\n it is also ineffective (kids don't need a single device to be \ncyberbullied\n) and puts responsibility on the victim, rather than the attacker (see victim-blaming, \npara\n. (7(c)) above).\n(17)\n&#xa0;&#xa0; \nThere is no single answer to this complex problem, but several smaller improvements can, collectively, advance online safety. I therefore recommend five ways forward.\n(18)\n&#xa0;&#xa0; \nIn a perfect world, we would always choose prevention over cure, but this requires well-informed vigilance both from potential targets and from those responsible for protection. At present, \nChildnet\n does outstanding work, teaching school-children to be safe \nand kind\n online, and I welcome the fact that online safety has been introduced across the 2014 National Curriculum.\n(19)\n&#xa0;&#xa0; \nFor best effect, however, these lessons need to be appropriately supported (see \nparas\n. (21)\n-(\n23) below), sufficiently detailed/thorough, and adopted across \nall\n schools (private, public, and free). These lessons also should not be restricted purely to Computing, but should be adopted across a number of classes, including PSHEE and Citizenship.\n(20)\n&#xa0;&#xa0; \nHowever, in order for this to be successful, teachers themselves need to be well-trained in the safety measures, in tell-tale signs, and in appropriate strategies of intervention. Teachers also need the support of parents and caregivers, and this leads into a second area of improvement.\n(21)\n&#xa0;&#xa0; \nThe assistance that \nChildnet\n currently offers teachers is also invaluable, but it could be substantially underpinned with compulsory online safety training in all PGCEs, since NSPCC research shows that far too many teachers currently don't feel confident when it comes to \nadvising pupils on safe social network practices\n.\n(22)\n&#xa0;&#xa0; \nMeanwhile, parents would benefit from proactive, face-to-face training in:\n(a)\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nsigns indicative of \ncyberbullying\n (whether as victim or bully);\n(b)\n&#xa0;&#xa0;&#xa0;&#xa0; \nways to keep children safe online\n (technologically, behaviourally);\n(c)\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nthe many organisations that offer help and advice (e.g. \nBeatBullying\n, \nChildline\n, \nChildnet\n, \nGet Safe Online\n, \nIWF\n, \nNSPCC\n, \nSIC\n, \nNHS\n, \nCEOP\n)\n(23)\n&#xa0;&#xa0; \nWhilst these organisations all do invaluable work, they cannot be a standalone solution. A third area of improvement, then, is through sites themselves.\n(24)\n&#xa0;&#xa0; \nWe generally expect social networks to offer the tools and support to keep us safe. Indeed, the expectation seems fairly reasonable. If Mr Smith wants to profit from people buying his goods or services, his products and premises must meet the relevant legal requirements to protect customers from loss and harm. However, should Mr Smith want to profit from people using his social network, in the UK at least there appear to be no similar legal requirements.\n(25)\n&#xa0;&#xa0; \nIt seems reasonable to argue that the opportunity to profit from a social network should also entail a duty of care towards that site's users. However, whilst most social networks require registrants to enter into agreements forbidding abusive behaviour, beyond that, sites differ widely in the availability, sophistication, and transparency of their safety features. At the most basic level, social networks should:\n(a)\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nallow users to control their own environment (e.g. privacy settings)\n(b)\n&#xa0;&#xa0;&#xa0;&#xa0; \nflag up content for the site to manage (e.g. report abuse buttons)\n(c)\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nproactively use their own management tools (e.g. IP blocks)\n(d)\n&#xa0;&#xa0;&#xa0;&#xa0; \npublish clear guidelines on how they will deal with complaints, handle abuse reports, and cooperate with criminal investigations\n(26)\n&#xa0;&#xa0; \nAt present, whilst some sites offer all of these and more, others provide none, and some even appear to \nstonewall those trying to tackle online abuse\n. This takes us into a fourth area of improvement – enforcement.\n(27)\n&#xa0;&#xa0; \nWhere cases become too serious for a user or site to deal with, we would naturally turn to the police. However, whilst \nSOCA\n does tackle cybercrime, its focus tends to divide between child sexual exploitation and online fraud. SOCA and the \nPolice Central e-Crime Unit\n are forming a new \nNational Cybercrime Unit\n, but it remains unclear whether online abuse will form part of this organisation's remit.\n(28)\n&#xa0;&#xa0; \nThis means that for now at least, online abusive messages and threats are more likely to be dealt with by ordinary police officers, and that makes it difficult for the average non-high-profile individual to find \nappropriately trained police who will take their complaint seriously\n. In short, it is vital that we have the necessary resources and training for police, including:\n(a)\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nPerception change\n: online offences are \"real crimes\" that should be taken seriously; users can't just resolve the problem by simply \"switching off\" (see \npara\n. (16) \nabove\n).\n(b)\n&#xa0;&#xa0;&#xa0;&#xa0; \nBasic training\n: unsurprisingly, non-specialist officers appear to be largely unaware of the sheer scope of online \"misbehaviours\" that exist, how online attackers work, their strategies of concealment, standard denial excuses (e.g. \"yes it came from my computer but I didn't send it\"), methods of gathering evidence, the investigation that needs carrying out, etc.. This is an issue that can only be resolved with extensive training. Without it, officers are likely to shy away from or find excuses for avoiding such areas, in turn institutionally embedding the concept that they only deal with \"real\" (i.e. offline) crime.\n(c)\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nMore resources\n: even were the above not an issue, officers also appear to be largely under-resourced in terms of time. The solution to this seems to be an extension to the remit of CEOP, SOCA, or the newly-proposed NCU (see \npara\n. (27) \nabove\n).\n(29)\n&#xa0;&#xa0; \nAssuming that a case is investigated by the police and the CPS decides to pursue criminal charges, many of the Acts that might by employed (e.g. \nMalicious Communications Act 1988\n, §5 of the \nPublic Order Act 1986\n, \nProtection from Harassment Act 1997\n, \nCommunications Act 2003\n) were created before the advent of major social networks, and so are imperfectly equipped to deal with the new behaviours that these sites have created.\n(30)\n&#xa0;&#xa0; \nFor instance, the most recent, relevant legislation, the Communications Act, came into force in July 2003. However, an Act of this magnitude—more than 250,000 words spanning over four hundred sections—takes years to write and enact. The section relevant to online behaviour (§127) is therefore far more heavily informed by the internet of the 1990s than that of the new millennium. Meanwhile, massive, ubiquitous social networks like \nFacebook\n and \nTwitter \nwere founded 2004 and 2006 respectively. As sites like these have evolved, so too have the behaviours associated with them, yet the legislation remains largely unchanged.\n(31)\n&#xa0;&#xa0; \nWhilst the CPS published \nguidelines\n on prosecuting cases involving communications sent via social media in June this year, like much current legislation designed for supposedly-similar offline behaviours, these guidelines do not explicitly address the critical differences that the online environment offers:\n(a)\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nthe speed with which content can be reproduced;\n(b)\n&#xa0;&#xa0;&#xa0;&#xa0; \nthe breadth and sensitivity (e.g. family, school peers) of audience that can be reached;\n(c)\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nthe inability of targets to entirely eradicate malicious content in some cases;\n(d)\n&#xa0;&#xa0;&#xa0;&#xa0; \nthe\n expense and difficulty (as outlined above) of prosecuting even very serious online offences.\n(32)\n&#xa0;&#xa0; \nIt is therefore worth considering whether these Acts need updating, or whether we actually need a new Online Communications Act that specifically covers the increasing range of abusive behaviours on the internet.\n(33)\n&#xa0;&#xa0; \nThis difficulty is further exacerbated by a culture in which offline crime still seems to be seen as more serious than any supposed online counterpart. For instance, the CPS provides useful guidance on behaviours such as \nstalking\n, \nharassment\n, and \nschool bullying\n, but if one reads these guidelines, it seems that the offline version is considered the norm, and any online variant, where it is even acknowledged to exist, is simply considered a sub-type.\n(34)\n&#xa0;&#xa0; \nThis overlooks the fact that supposedly equivalent behaviours like \ncyberstalking\n, \ncyberharassment\n, and \ncyberbullying\n can have their own unique attributes, methods, and consequences which \nrequire dealing with in fundamentally different ways. Indeed, what little the CPS has to say about online antisocial behaviours tends \nto be vague\n.\n(35)\n&#xa0;&#xa0; \nIn short, it appears that we need CPS guidance for the police, court system, legal practitioners, etc. that would provide definitions for, and explanations of the various antisocial online behaviours (e.g. trolling, \ncyberbullying\n, \ncyberstalking\n, etc.), and information with regards to issues of jurisdiction and proof.\n(36)\n&#xa0;&#xa0; \nFinally, across the European Union, the \nSafer Internet Programme\n is promoting \nself-regulation\n, and already, several high-profile corporations have signed up to a set of \nSafer Social Networking Principles\n. This is a great start, but these principles are purely voluntary, and whilst it would be inappropriate to enforce such principles across all EU-based social networks, it is worth returning to the example of Ms Smith, and to ask whether those profiting from social networks should have similar duties of care towards their site users.\n(37)\n&#xa0;&#xa0; \nThe full potential of the internet is yet to be realised. If we are to fully enjoy the benefits, and reduce online threatening and abusive behaviour, my belief is that we must approach this in a comprehensively and holistically. I hope the above may offer some ways in which to achieve this.\n&#xa0;\nSeptember 2013\n              \n              \n"