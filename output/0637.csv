&#xa0;
default&#xa0;
defaultJoint written evidence submitted by defaultAdam J L Harris, Nigel Harvey, Leonard A Smith, defaultDavid A Stainforth, Erica Thompdefaultson default(CLC018)defaultExecutive Summary
defaultOur main aim is to address the following point in the call for evidence from the Science and Technology Committee inquiry into “Climate: Public understanding and policy implications”:
defaultWe begin by discussing the wider context of the challenges and relevance of public engagement with science and with scientific uncertainties. We go on to comment on the way uncertainties in future climate are often characterised today. 
defaultWe end
default with 
defaultdiscussion of 
defaultsome significant issues regarding the character of climate prediction uncertainties and their relevance for public understanding.
defaultTo increase public trust in the results of climate science, w
defaulte recommend that the uncertainties inherent in climate forecasts be made explicit. In cases where these uncertainties can be legitimately expressed as
default probabilities, we suggest that use of a dual verbal/numerical format for expressing uncertainty (e.g., 
default‘
defaultlikely (65-80%)
default’
default) will enhance communicative effectiveness. 
default We also 
defaultpropose 
defaultuse of the verbal confidence scale developed by the 
defaultIntergovernmental Panel on Climate Change for their 
defaultFifth Assess
defaultment Report
default, especially important i
defaultn cases where there are underlying problems in expressing the uncertainties as probabilities
default. Finally, we see the media as having a role in helping the public understand how forecasts are generated from models of the climate and, more particularly, 
defaultthe degree to which
default diversity in outputs from these models reflects uncertainty in those forecasts.
default 
defaultBrief Introduction
default to Submitters
defaultThis evidence has been collated by f
defaultive
default people with relevant expertise. Adam Harris is a Lecturer, in the Department of Cognitive, Perceptual and Brain Sciences at UCL. He has published research on the communication of environmental risks within the context of climate change. Nigel Harvey is Professor of Judgment and Decision Research at UCL and Visiting Fellow in the Department of Statistics at LSE. 
defaultHe has published research on the role of judgment in forecasting
default, on determinants of trust,
default and on the quality of subjective estimates of probability. Leonard Smith is Research Professor in the Department of Statistics at LSE and Director of the Centre for
default the Analysis of
default Time Series. He is also a Programme Director at the Centre for Climate Change Economics and Policy
default and Senior Research Fellow at Pembroke College, Oxford
default. He has published widely on the 
defaultrole of models in weather and climate research and on the interpretation of ensemble forecasts derived from such models. David Stainforth is Senior Research Fellow at the Grantham Research Institute on Climate Change and the Environment at LSE
default, where he is on the lead staff of the Global Response Strategies Research Programme
default. He co-founded and was chief scientist on the climateprediction.net project, the world’s largest climate modelling experiment. 
defaultHis work focusses on how robust and useful information can be extracted from climate modelling experiments and on how to relate climate science to real-world decision making so that it will be of value to industry, policy makers and wider society.
default E
defaultrica Thompson is a Research Officer in the Centre for the Analysis of Time Series
default, working on the Munich Re Programme evaluating climate risks and opportunities.
default&#xa0;
default&#xa0;
defaultBasis for recommendations
defaultIntroduction
default1. 
defaultPolicy makers are frequently consider
defaulted
default the primary consumers of statements about future climate. 
default 
defaultP
defaultublic support for policies
default, however
default, is
default 
defaultcritical
default 
defaultto ensure their smooth implementation: they will be more effective if people comply willingly with them
default. Such support
default 
defaultdepends on people’s trust in both policy makers and their scientific advisors. T
defaulthat t
defaultrust
default, in turn, depends 
defaultboth 
defaulton 
defaultperceived competence and 
defaulton 
defaultperceived benevolence of motives: policy makers and their advisors may be mistrusted either because they are seen as well-meaning but incompetent or as competent but with a hidden agenda 
defaultthat favours vested interests.
default 
default2. Greater trust in scientific estimates of climate change is likely not just to increase support for government policies addressing it but also to lead to an increase in personal behaviours that may mitigate it. For example, people may reduce car use or increase home insulation.
default3. 
defaultPrevious problems with policies based on uncertain science have arisen because people were given the impression that our knowledge was more certain than it was (BSE) or because, consequ
defaultent on this, they did not trust
default 
defaultassurances that our knowled
defaultge had a firm basis when it act
defaultually did 
defaultso 
default(MMR). 
defaultThe lessons we need to learn from these events are that 1) we need to make levels of uncertainty associated with the science underpinning our policies 
defaultexplicit and 2) we need to make 
defaultour rationale for those
default uncertainty estimates expli
defaultcit
default.
default 
defaultWe need to do these things to increase trust. As Paul Slovic has pointed out, transparency (not withholding information) i
defaults a
default fac
defaulttor
default that increases trust: it reassures people that there is no hidden agenda
default.
default4
default. C
defaultlimate modellers have developed a number of techniques that allow them 
defaultto produc
defaulte estimates of unce
defaultr
defaulttainties
default associated with different degrees of climate change under specified assumptions. 
default 
defaultC
defaultlimate scientists 
defaultdo not
default,
default 
defaulthowever, always 
defaultconsider 
defaultthe diversity of their models to 
defaultre
defaultf
defaultlect 
defaultprobabilities 
defaultexpressing 
defaultuncertainties
default associated with 
defaulttheir 
defaultforecasts.
default  Moreover, a
default model-based estimate of probability is always incomplete without an accompanying 
default(quantitative) 
defaultestimate of our confidence that the model is able to provide meaningful information
default.
default To put this the other way round, as is often the most usefu
defaultl way of presenting it, what is
default 
defaultt
defaulthe probability that the model is misinformative
default?
default5
default. It is also important to recognise
default that different aspects of the climate problem have different character
defaultistic
defaults of uncertainty. Basic science is sufficient to know that continued anthrop
defaulto
defaultgenic emissions of greenhouse gases at the current rate will lead to 
defaulta warmer planet and 
defaultclimate disruption with severe negative consequences for society. The details of how that will play out and the detailed national benefits of any particular miti
defaultgation policy is still an area 
defaultwith substantial and conceptual uncertainties.
default6
default. 
defaultIn summary, 
defaultpeople
default must feel that current knowledge
default is reasonably sound, 
defaultthat its limitations are being honestly communicated to them
default, and that policy makers take account of these limitations. This, in turn, implies that the public should somehow be made aware of the uncertainty estimates associated with climate forecasts
default 
default(
defaultincluding the uncertainty in so
default-
defaultcalled probabilistic projections
default) 
defaultand 
defaultthey should be helped to understand how we
default can have confidence in the big picture without being able to predict the details. 
defaultWe now turn to problems associated with communicating 
defaultthis 
defaultuncertainty.
default7. Climate models have been used to produce “probability estimates” but 
defaultthese 
defaultestimate
defaults
default come from different 
defaultmethods with different 
defaultassumption
defaults
default and 
defaultoften 
defaultdifferent models
default. We do not yet have methods to provide robust probabilities for many detailed aspects of 
defaultfuture 
defaultclimate change.
default Thus, there are two distinct challenges: one is to communicate probabilities when we have them; the other is to communicate uncertainty when such probabilities are not available. 
defaultCommunication of probabilistic 
defaultinformation
default8
default. 
defaultTo address th
defaulte first challenge
default, t
defaulthe Intergovernmental Panel on Climate Change (IPCC) adopted a policy of providing an explicit mapping between seven verbal terms and seven ranges of probability. 
defaultThe probabilities could then be expressed in verbal terms. 
defaultThus,
default in the IPCC mapping
default, ‘virtually certain’ refer
defaults
default to probabilities in the range 99 – 100% whereas ‘
defaultlikely
default’
default 
defaultrefer
defaults
default 
defaultto probabilities in the range 66
default –
default 100
default%. 
defaultThis approach allowed results from experts who disagreed about precise numerical probabilities to be expressed in the same verbal terms. Thus, an expert who associated a probability of 70% with a particular future event and another expert who associated a probability of 90% with that event could both be said 
defaultto assess the event as being ‘likely’.
default9
default. However, there are 
defaulta number of 
defaultproblems 
defaultassociated 
defaultwith translating probabilities into verbal terms. 
defaultFirst, t
defaulterms, such as ‘virtually certain’ and ‘very likely’, are 
defaultintuitively 
defaultmatched up to different ranges of probability by different people. Thus, ’very likely’ may refer to probabilities in the range 85 – 95% for one person but to 70 – 85% for another. 
defaultOf particular relevance here
default, recent studies have shown that the particular mapping adopted by the IPCC is not consistent with how people naturally use the probability terms included in the IPCC mapping. 
defaultFurthermore
default, the range of probabilities associated with particular verbal ex
defaultpressions depends on various 
defaultother factors, such as the seriousness and the expected frequency 
default(base rate) 
defaultof the event to which the term refers
default. Thus
default 
defaulte
defaultxpressions referring to more severe outcomes are interpreted as denoting a higher probability
default.
default10
default. Given these problems with translating probability information into words, why should it not be communicated in its raw numerical form? There are two arguments against this. First, 
defaulta single probability may give the impression that uncertainty estimates are more accurate than they are. This can be countered by using numerical ra
defaultnges of probabilities (e.g., 70 – 
default85%). Second, it is sometimes 
defaultclaimed that residents of the United Kingdom cannot easily understand probabilities and that information (e.g., weather forecasts) should therefore not be given probabilistically.
default To address this, both verbal terms and a range of numerical probabilities could be used to express the uncertainty associated with a particular event. Thus, an event could be labelled as ‘likely (65 – 80%)’. Providing information in this dual form would supply probability information to those who can benefit from it without removing the verbal expressions of uncertainty from those who cannot.
default11
default. 
defaultPeople need not be given probabilities (or ranges of probabilities) for partic
defaultular events. D
defaultecisions usually need only an estimate of the likelihood that some critical threshold for a particular impact is exceeded. 
defaultUncertainty expressed in this way also provides a succinct message that the public are likely to understand easily: for example, 
defaulta hypothetical 
defaultmessage that “it is likely (65 – 80%) that, 
defaultwithout significant global emissions reductions
default, the flood risk in England will increase 
defaultover the next 100 years
default”
default 
defaultis sufficiently clear and concise to be appreciated by most of the population.  
defaultThere are 
defaultalso 
defaultreasons to have greater confidence in 
defaultprobabilities that thr
defaulte
defaultsholds will be
default exceeded.
defaultThe problem of uncertainty
default12
default.
default 
defaultT
defaulthe se
defaultcond challenge noted above concerns situations in which
default firm probabilities are not available
default. T
defaulthe question 
defaulthere 
defaultis deeper than how one would communicate them if they were
default available
default.
default To discuss this point, we need to outline briefly why probabilities may not be available
default, and we outline 
defaulttwo 
defaultways of dealing with
default uncertainty/diversity in probabilistic estimates in the next two paragraphs
default. 
default 
default13. One way of assessing some of the uncertainty is to allow the initial values entered into a particular model, and the parameters in the model, for each simulation, to be taken from distributions of values. Once a sufficiently large number (an “ensemble”) of forecasts has been produced, the proportion of those forecasts having some characteristic, such as showing a temperature increase of two degrees or more, is sometimes treated as an 
defaultestimate
default of the probability of that characteristic at whatever horizon for which the forecasts were made. (Significantly, more effective methods than simple counting are used in practice.)
default1
default4
default. 
defaultF
defaultor some variables, predictions from different climate models diverge
default considerably
default but, for other variables
default, there is greater consistency
default across such a “multi-model ensemble”
default.
default 
defaultThe language of “confidence” is more appropriate for expressing the difference in degree of uncertainty when model forecasts are in conflict; the probability that each individual model forecast is believed realistic is also of value.
default  
defaultImportantly, i
defaultt is simply not 
defaultthe case that these
default 
defaultensembles encapsulate
default all types of uncertainty involved in forecasts
default.
default 
defaultT
defaulthus
default,
default 
defaultthey provide 
defaultat best 
defaultincomplete
default estimates of probabilities for the outcomes of interest
default 
defaultunder clearly vetted conditions 
defaultand
default,
default at worst
default,
default excuses for false confide
defaultn
defaultce
default.  
defaultWhile they may
default be a more 
defaultreliable guide
default than pure judgment
default,
default just how good a guide 
defaultthey are 
defaultremains an issue of debate
default,
default 
defaulteven in th
defaulte case of seasonal forecasting (
defaultand
default,
default of course
default,
default we 
defaultcan 
defaulthave no relevant empirical evidence in climate
default forecasting on which to assess them).
default  
default 
default1
default5
default. 
defaultThe process of model-building starts with the most robust and familiar aspects of the prob
defaultlem under consideration and then develops
default 
defaultover time 
defaultto incorporate more and more of the less-well-understood effects.  It is therefore plausible that, as models become more advanced and more 
defaultdetail
defaulted information
default 
defaultis expected of the
defaultir
default output, 
defaultthe diversity of outcomes increase. L
defaultevels of uncertainty 
defaultwill appear to 
defaultincrease
default if we have not allowed for, or worse, have suppressed, likely shortcomings in today’s models
default. 
default 
default16
default. 
defaultThere is a spectrum of confidence 
defaultin climate predictions. These range 
defaultfrom the globally-averaged quantities in which we have reasonable confidence
default,
default to regional impacts for which we have a very high level of uncertainty
default, all hinging on the assumption the models have high fidelity. 
default  Initial value ensembles and 
defaultperturbed 
defaultparameter ensembles 
defaultshow us 
defaultthe diversity in current 
defaultmodel
default behaviour
default.  Multi-model ensembles such as the IPCC use also help 
defaultus 
defaultto understand possible dependence of results on model structure, but the number and independence of these models are very limited
default and 
defaultt
defaulthe IPCC itself does not interpret t
defaulthe ensembles to reflect the pro
defaultbable range of reality
default 
defaulteven for global mean temperature
default. 
default  
defaultThus, we should not communicate the diversity of model simulations as if it were the uncertainty in our future, unless we believe that diversity reflects a probability that genuinely provides a basis for action
default; this is not the case for today’s models
default. 
defaultW
defaulte can
default, however, 
defaultsay that we have more confidence in results which are common to all model structures
default, while noting that the fact these models share known common errors limits our ability to quantify this increased confidence. 
defaultI
defaultn such cases, we need to inform the public of our confidence in the scientific results
default, not just 
defaultthe 
defaultuncertainty
default from today’s modelling experiments
default. How should this be done?
default17. 
defaultFor the IPCC fifth 
defaultassessment 
defaultreport, lead authors are told that: “confidence should not be interpreted probabilistically” (page 3).
default Instead, it should reflect the type, amount, quality and consistency of evidence and the extent to which different experts agree on it.  These should be assessed and used to assign confidence into one of five categories (very low, low, medium, high, very high). 
default18. 
defaultAlthough criteria for correct assignments are suggested, it is clear that confidence assessment is a highly subjective process
default, reflecting the subjective nature of the uncertainty itself
default.
default  In other words, 
defaultthe uncertainty
default that we have is concerned with 
defaultour own lack of knowledge about the system, not a property of the system itself.
default There are two levels of 
defaultthis uncertainty:
default the uncertainty reflected in the diversity of our current models, and the chance that, for a particul
defaulta
defaultr time and forecast, our 
defaultc
defaulturrent models are 
default(un)
defaultable to provide realistic simulations at all.
default Our confidence assessments need to reflect both of these.
defaultRecommendations
default19. To increase public trust in the results of climate science, we recommend that the uncertainties inherent in climate forecasts be made 
defaultpublicly 
defaultexplicit
default and discussed openly.
default20. In cases where 
defaultclimate 
defaultscientists consider that these uncertainties can be legitimately expressed as probabilities, we suggest that use of a dual verbal/numerical format for expressing uncertainty (e.g., ‘likely (65-80%)’).
default21. 
defaultI
defaultn addition to that, or as the sole measure i
defaultn cases where climate scientists consider that t
defaulthe uncertainties 
defaultcannot be legitimately expressed 
defaultas proba
defaultbilities, we propose that the verbal 
defaultscale developed by the Intergovernmental Panel on Climate Change for their 
defaultFifth Asses
defaultsment Report
default is
default used to communicate confidence in forecasts 
defaultand the science underlying them
default.
default22. Greater public trust in results of climate science is more likely to develop if the pu
defaultblic understand 
defaultbetter the processes of scientific research and the use of computer models in such endeavours; 
defaultin 
defaultparticular the characteristics of different types of uncertainty
default in climate science
default. 
defaultWe recommend that the media give greater attention to this issue
default, more clearly distinguishing what is near certain and what is uncertain and likely to change
default;
default as well as how the two can live side by side in the same field of scientific research without contradiction
default.
defaultApril 2013
default&#xa0;
default