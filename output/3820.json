"&#xa0;\nWritten Evidence from Simon Guilfoyle [CST0026]&#xa0;\nPersonal StatementIn submitting this evidence, it is not my intention to simply add to the examples of mis-reporting of crime incidences that the Committee \nhas already considered\n. Furthermore, I do not intend to address all six questions, rather\n to\n offer a perspective specifically in relation to Question 2:\n“What are the factors\n that can influence police mis-recording of crime?”\nMy answer \ndraws upon\n on academic research into UK police performance management \nthat I am currently conducting\n as part of my PhD studies at Warwic\nk Business School, as well as \nmy professional experience as a serving\n police\n officer of 18 years. I \nwish to clarify however, that \nthe\n e\nvidence is presented\n on my own behalf, rather\n than on\n behalf of my force, West Midlands Police.\n \nMy aim is to provide an insight into the root causes of police mis-recording of crime, to enable greater understand\ning\n of the factors responsible\n,\n and to e\nncourage debate about how\n future reoccurrences can be prevented.\n&#xa0;Introduction and Summary1.\n \nThis paper will examine the factors that influence police mis-recording of crime, addressing the following themes in sequence:\nContext2. In or\nder to appreciate the impact of current day police performance practices and resultant behaviour, it is necessary to understand the evolution and recent history of UK police performance management; what follows is a brief summary. \n3. \nThe roots of modern d\nay police performance management in the UK can be traced to the early 1980s, and \nthe drive\n to demonstrate efficiency, economy and effectiveness. This heralded the beginning of a paradigmatic shift towards managerialism across the UK police service, which c\name into being as part of wider public service reforms of the era, known as \nNew Public Management (NPM). (See Hood, 1991, \n1995, \n1996, 1998; Pollitt and Bouckaert, 2000; Pollitt, 2002\n; Guilfoyle, 2012)\n4. \nNPM-based practices intensified throughout t\nhe 1990s\n and into the 2000s. In 1994, t\nhe \nPolice and Magistrates Cou\nrt Act (Home Office, 1994)\n conferred autho\nrity upon the Home Secretary to,\n “…to direct police authorities to es\ntablish levels of performance (‘\nperformance targets\n’\n) to be aimed at in seeking to ac\nhieve the objective”. (Home Office, 1994, p.16) \nThis marked a shift toward centralised control through the application of targets, which came to characterise police performance management during subsequent years.\n5. \nPost 1997\n, \nNPM-orientated performance no\nrms were further consolidated through the vigorous application of\n performance indicators, numerical targets, \n‘league tables’\n, audit and inspection, \nand \nthe holding to account of individuals for perceived ‘poor’ performance. (Loveday, 1998; 2005)\n As part of\n the \n1998 Comprehensive Spending Review (CSR), 366 Public Service Agreements (PSAs) were introduced across the public sector, which included over 600 performance targets. (Chief S\necretary to the Treasury, 1998a,\n 1998b; James, 2004)\n6. \nThis was followed by the \nPolice Reform Act of 2002 (Home Office, 2002), which \nheralded\n a \nfurther \nintensification of NPM-based practices\n. (\nJones\n, 2\n003\n) The Act:\n“…provided the Home Secretary with powers to set national police priorities, remove chief office\nrs and directly intervene in the management of local police services”. (Loveday, 2006, p.284)\n7. \nInterventionist tactics adopted by bodies set up\n to scrutinise forces\n (for example, the \nPrime Minister’s Delivery Unit (PMDU)\n and\n the \nPolice Standards Unit (PS\nU)\n)\n, \nto assess\n performance against targets\n,\n and expose ‘poor performers’\n continued throughout the\n first decade of the 21\nst\n Century. \n(Hood and Dixon, 2010)\n Forces were assessed against criteria set out within the new \n‘Policing Performance Assessment \nFramework’ (PPAF) (Home Office, 2005),\n \nwhich was superseded by\n the \n‘\nAssessment of Policing and Community Safety\n’\n framework (APACS), amongst others.\n \n(Home Office, 2007)\n8. Following the abolition of APACS in 2010, government policy has moved away from centr\nally-imposed numerical targets, although they are still widely-applied within police forces, as well as by a number of PCCs. Her Majesty’s Inspectorate of Constabulary\n (HMIC) also retains peer comparison\n methodology \nthat is \nbased on a ‘league table’ approa\nch, which ranks forces against each other. Therefore, despite this policy shift at the national level, the legacy of \nNPM-orientated\n practices \nhas helped perpetuate a\n dominant mode of performance management that is ingrained within the police psyche.\n9. \nThis is the context within which gaming and other dysfunctional behaviour associated with police mis-recording of crime has occurred.\nPolice Performance Measurement and Its Prevailing Characteristics10. Effective performance measurement and management sys\ntems are necessary for multiple reasons. Davis (2012) emphasises:\n“Performance measures are a primary method of ensuring that the police are held accountable in democratic societies”. (\nDavis, 2012, \np.3)\n11. \nEvidence of performance is necessary to ensure a\nc\ncountability and transparency\n, which is vital in fostering policy legit\nimacy.\n Using the right measures in the right way also helps managers understand how the system is performing, thereby enabling a cycle of continuous improvement. (See Deming, 1986, 1994\n)\n12. Due to the difficulty in quantifying outcomes in complex public service environments, police performance information has tended\n to focus on quantitative numerical dat\na and is heavily reliant upon proxy measures. This carries significant risks when at\ntempting to assess performance, but is further hampered by common practices relating to how the data is routinely presented and used. Coupled with perverse incentives associated with numerical targets and league tables, these practices significantly increa\nse the likelihood of \ngaming, such as in the case of crime being mis-reported. \n13. \nIn UK policing, there are three dominant components that contribute towards this risk. I refer to them as the ‘three pillars’ of traditional police performance management. T\nhey are:\n14. \nTaken in isolation, each has the potential to \nseverely distort activity, damaging service delivery and inadvertently encouraging dysfunctional responses. They will now be examined in turn.\nBinary Comparisons1\n5\n. The\n practice\n of making binary comparisons\n involves comparing two isolated numeric values, \nthen interpreting the difference between them as though it were a trend. \nSuch c\nomparisons are routinely made with\n \nlast week, last month, last quarter, the average, the cumulative year-to-date figure, and so on. The outcome is that a single numeric value or\n percentage change is \npresente\nd as though it represents a confirmed trajectory within the data.\n1\n6\n. \nThe following \nexamples\n are typical:\n“…\ncrime has been reduced by 10% across the force area. This is 3,963 fewer victims of crime compared to the previous 12 \nmonths...” (North Yorkshire Police, 2013)\n“The number of house burglaries reported to police fell by 36 per cent during Operation Brightshadow, which ran from Monday, October 3 to Sunday, October 9, compared to the week before”. (Essex Police, 2013a)\n17.\n \nB\ninary comparisons tend to be used because of their si\nmplicity. They appear to convey \ninformation about ‘direction of travel’, and make for easy-to-consume quasi-statistical performance information. The danger of using them, however, is that they are \ntoo\n si\nmplistic. \nBird \net al\n (2005) warn that the\nir\n use encourage\ns\n over-interpretation \nof very minor changes amidst\n data, leading to false conclusions. They strongly caution against the practice, noting:\n“Very particularly the practice of concentrating on a compar\nison with the most recent value, this year’s results compared with last year’s, may be very misleading for reasons including regression to the mean”. (2005, p.14)\n18\n. \nEssentially, the inadequacies associated with binary comparisons make the approach fundam\nentally incapable of conveying any useful information\n whatsoever\n.\n Despite this, the practice is probably the single most common method of presenting performance data in UK policing. \nThe practice also invites\n unintended behavioural changes\n, which\n occur because assumptions about performance based on a binary comparison are often accompanied by implicit exhortations to improve. \nA typical example would be where crime appears to have increased, when in fact data presented in a time series may indicate\n it is stable. Performance pressures associated with \nsuch \nan apparently increasing crime rate are one of the factors\n directly\n responsible for mis-recording of crime. \nTabular Peer Comparisons (‘League Tables’)1\n9\n. \nLeague tables form part of commonly-used a\npproaches for assessing comparative performance, yet are vulnerable to methodological instabilities which undermine their efficacy; their use can also lead to unwarranted conclusions being drawn about performance, and act as an unintended catalyst for unhe\nalthy internalised competition and dysfunctional responses.\n (Jacobs and Goddard, \n2007\n; Goldstein and Spiegelhalter, 1996; Bird \net al\n 2005)\n20\n. \nTh\ne rationale behind \ntheir application in policing\n \nis outlined \nas follows:\n“The intention is not to ‘set’ one \nindividual force against another nor to use the performance indicators as a proxy for increasing inter-force competition, but rather to broaden the scope of management tools open to senior officers in the context of improving individual force performance”.\n (Barton and Beynon\n,\n 2011, p.363)\n2\n1. \nNevertheless, the probability of gaming (such as \ndeliberately under-recording crime) is heightened when league tables are used as a tool to compare peers.\n \nHood (2007)\n, for example\n warns:\n“Like target systems, they are \nlikely to produce output distortions as producers learn to find ways that move their organizations up the league tables in ways that do not reflect the intentions of those who framed the rankings, or ignore non-measured activities”. (\n2007, \np.101)\n22.\n \nBehav\nioural changes are an inevitable consequence of league tables. When they are used in a performance environment alongside the expectation of continual crime reduction, the incentives and pressures integral to the league table approach can influence behaviou\nr to the extent that the \nde facto\n purpose for activity becomes to avoid low league table rankings.\n2\n3\n. \nDe Maillard and Savage (2012) note:\n“…the core rationale for police performance tables is more a reflection of a strategy of ‘naming and shaming’ - an \nattempt to drive up performance by identifying the best and worst performing police organisations”. (2012, p.367)\n2\n4\n. Whilst the intention of policy makers would be that organisations are spurred on by these poor rankings to improve actual performance, the\n evidence points towards widespread gaming and other dysfunctional behaviour being induced as a direct consequence. (See Bevan and Hood, 2006; Hood, 2007; Rothstein 2008)\n It is suggested that the widespread practice of using league tables in UK police perf\normance management is one of\n the contributory factors in\n case\ns\n of police mis-recording of crime.\nNumerical Targets2\n5\n. \nThe use of numerical targets in police performance management systems is still endemic, and it is my claim that they are the “…single mos\nt pernicious element of conventional management practice…” (Guilfoyle, 2013, p.163) Nevertheless, \nexponents claim \nnumerical \nt\nargets \ncan\n enhance managerial responsibility, motivate workers, and foster public accountability. (Capon \net al\n, 1987; Jennings and Haist, 2004) \nNPM \nreformers and \nproponent\ns \nof Goal-Setting Theory \nc\nlaim that\n target\n-driven performance management \ncan improve performance,\n \nas well as \nenhance transparency, accountability and legitimacy. (\nLocke, 1968; Locke \net al\n, 1981, \n1989; Locke and Latham, \n2002, 2006; \nHoque \net al\n 2004)\n2\n6\n. \nA wide range of r\nesearch suggests\n however,\n that \ntarget\ns \ndo not\n improve p\nerformance in complex operating\n environments. \nMoreover,\n some studies indicate\n targets can actually impede performance. (\nKanfer\n and Ackerman\n, \n1989) Earley \net al\n (1989) conclude targets do not improve performance for complex tasks. \nSimilarly\n, Horton and Smith (1988) and Mackenzie and Hamilton-Smith (2010) point out complex systems do not respond well to target-\ndriven \nperformance ma\nnagement, whilst Loveday (2006)\n argues\n:\n“…public services… are often best described as complex human activity systems; these cannot be managed by crude performance targets”. (2006, p.287) \n2\n7\n. \nNumerical targets \nundermine the effectiveness of police performance management systems \nbecause\n they are\n \ncompletely \narbitrary\n; \nneither do they\n provide a method nor\n capacity for achieving organisational aims. Moreover, they \nact as a trigger for \nbehavioural change; indeed,\n the\nir \npurpose\n is to change behaviour. Bevan and Hood (2006) observe:\n“Governance by targets rests on the assumption that targets change the behaviour of individuals and organizations…” (2006, p.8)\n28\n. \nT\nhere is a growing body of evidence that indicates many of\n the behavioural changes triggered by target-driven performance management are damaging and dysfunctional.\n \n(\nSee Deming, 1986, 1994; Smith, 1990, 1995; Pidd, 2005; Bevan and Hood, 2006; Hood, 2006, 2007; Loveday, 2006, 2008; Rothstein, 2008) \nNotably, \nGoodha\nrt’\ns eponymous Law (1975) states:\n“Any observed statistical regularity will tend to collapse once pressure is placed upon it for control purposes”.\n \n(Goodhart, 1975)\n2\n9\n. \nThe inference is that in the case of target-driven performance management, pressure to meet targets \nleads to\n counterproductive reactions, leading to statistical and behavioural distortions.\n This is precisely what drives police mis-recording of crime; as lo\nng as targets remain for crime reduction, the risk of this type of behaviour remains high. \nThis is because\n:\n“The difficulty with target setting is that despite the good intentions of the target setters, finding a successful strategy to meet targets becomes\n th\ne focus of the delivery manager…\n” (\nGhobadian \net al\n,\n \n2009, p.1530)\n \n30\n. \nFurthermore, research suggests\n that implicit incentives (i.e.\n rewards and sanctions) typically present within target-driven performance \nmanagement\n increase the likelihood of unethical \nbehaviour\n. For instance, Schweitzer \net al\n (2004) \nargue\n \nspecific goals (i.e. \nnumerical targets\n)\n are known to drive improper behaviour\n,\n s\nuch as falsification of records. Bandura (1999) contends\n p\nerformance goals can caus\ne moral disengagement\n,\n leading to unethical \nconduct\n, whilst Barsky (2008) explicitly warns:\n “Goal difficulty and specificity are related to unethical behavior, such that exposure to increasingly difficult and specific goals will negatively impact ethical recognition, thereby increasing the likelihood of unethical behavior”.\n (2008, p\n.70\n)\n31\n. \nIt i\ns important to \nrecognise\n, however, that ‘everyday’ decisions about whether to record an incident as Offence Type ‘A’ or Offence Type ‘B’ can quite legitimately \noccur within\n an \n‘\noverlap \nzone’\n, where either offence \nclassification can\n theoretically \nbe correct\n. Therefore, whilst the Committee has heard evidence of serious offences \nallegedly \nbeing downgraded or mis-recorded, I would posit that much ‘under-reporting’ falls into this ‘technical’ cat\negory, where there might be\n l\nimited direct\n impact on the public. \n3\n2\n. \nA\n hypothetical\n example \nc\nould be the case of a person who is arrested for disorderly behaviour \nin a town centre whilst drunk; t\nhe non-recordable offence \nof Drunk and Disorderly may be\n appropriate\n for dealing with the matter\n, as might\n a recordable offence under Section 5 of the Public Order Act 1986. The point\n,\n though, is that where there exists\n an implicit performance pr\nessure to reduce crime, this can\n introduce an incentive to classify the matt\ner as D&amp;D rather than Section 5, as the \nformer does not count towards crime figures.\n This risks distorting the intelligence picture relating to crime patterns, which is a necessary source of information for determining operational responses.\n3\n3\n. \nWhether\n instances \nof mis-recording \nare relatively \ninnocuous, or downright unethical, the \nprimary \ntrigger\n remains\n the same – numerical targets.\n \nEvidence from within policing (and across the public sector) confirms targets \nare \nconsistently \nresponsible for generating\n widespread\n unintended \nconsequences, \ndysfunctional behaviour and collateral damage\n.\nResponses to the Problem3\n4\n. Concerns about \nsuch adverse consequences h\nave rightly been raised by the Committee, and it is appropriate that steps are taken to prevent reoccurrences. Traditional \napproaches to \nm\nitigating \nperverse outcomes\n tend to rely on audit and inspection regimes, sanctions, greater scrutiny, new policies, additional levels of authorisation and the restriction of professional judgment at the frontline. \nHood (2006) observes that\n \ngovernment\nal\n response\ns\n to\n identified\n instances of gaming ha\nve\n been punitive, prescriptive, \nand indicative of \nlow trust\n;\n \nfor example, the enactment of\n more rules\n and\n doctrine.\n35\n. \nThese\n responses, however, are unlike\nly to prevent the types of \nmis\n-\nreporting of crime\n abo\nut which\n t\nhe Committee has heard evidence\n. This is because the traditional approach of identifying and punishing individuals who have engaged in these behaviours does not address the underlying triggers or latent system conditions that make them likely; ev\nen predictable. \n3\n6\n. \nIn considering organisational error, \nReason (2000) \nargues t\nhat there are two main approaches to the problem;\n \nnamely, the \nperson approach\n and the \nsystems approach. \nThis notion is as relevant to understanding institutionalised deviant behaviour as it is in the case of \nsimple \nerror. \nThe dominant tradition of apportioning blame to individuals is indicative of the person approach; conversely, the systems approach suggest\ns that the overriding cause\ns\n of organizational failings \nare rooted firmly in the design of the system \nand the latent conditions prevailing \nwith\nin it. \nParticularly, \nSpitzer (2007) contends that the performance management climate of an organisation is the \nsi\nngle greatest infl\nuencing factor on culture\n and behaviour\n.\n3\n7\n. Therefore, it is important that the response to the examples outlined in evidence provided \nto the Committee\n \naddresses\n the fundamental systemic triggers and incentives \nthat \ninadvertently \nencourage\n \npolice \nmis-recording\n of crime. The evidence pertaining to the last thirty years of p\nolice\n performance management suggests that gaming and dysfunctional behaviour is a widespread and inevitable consequence of performance management systems that ar\ne predicated on the \n‘\nthree pillars\n’\n of binary comparisons, league tables and numerical targets.\n It is these ingrained practices that must be challenged, rather than merely the symptoms that manifest themselves in the \ntypes of \nbehaviour subject to the I\nnqui\nry.\nConclusion and Future Direction3\n8\n. \nF\ninally\n, whilst the dysfunctional practices outlined can be traced to these three pillars, \nit is not my contention that performance management or measurement is a bad thing. It is absolutely necessary to measure \nperformance in order to understand how the system is performing. Evidence of good performance fosters legitimacy and leads to organisational improvement through the sharing of good practice. S\ncrutiny of data\n is necessary to aid transparency and accountabil\nity. Additionally, there is a practical dimension to the collation and analysis of crime data, as it enables managers to interpret trends, understand anomalies and instigate an evidence-based response to confirmed patterns. \n3\n9\n. \nThe issue, however, is \nhow\n \nthis has largely been done in UK policing. The use of binary comparisons, league tables and numerical targets has \ngenerated\n a legacy of performance management systems which are dominated by characteristics known to make accurate data \ninterpretatio\nn impossi\nble\n, as well as\n drive dysfunctional and even unethical behaviours that work against the system and damage public confidence.\n40\n. \nFor this reason, I propose the removal of all numerical targets from police performance frameworks; the only way\n to \nsuccessfully\n \nmitigate\n police\n mis-recording of crime statistics is to remove the incentive for doing so. \nIt is also necessary to\n rethink \nthe current use of league tables which attempt to neatly separate forces into ordered rankings, as well as the use of bi\nnary comparisons.\n \n41\n. \nAs an alternative, \nI \nendorse the adoption of Systems Thinking principles, and promote\n the \nwider \nuse of Statistical Process Control \n(SPC) \ncharts as a method for unders\ntanding crime data\n. This\n allows for \nmuch more sophisticated\n data in\nterpretation\n and appreciation of systemic influences and interdependencies,\n \nwhich\n should frame performance conversations at all levels.\n \n4\n2\n. \nThe removal of the \ntriggers\n responsible for police mis-recording\n of crime \nis the \nonly \nway to effectively \naddress \nthe systemic latent conditions that incentivise the practice.\n \nReplacing the blunt and counterproductive tools of traditional police performance management with SPC-based methodology has the potential to signal a paradigmatic shift that \nsh\nould\n significantly\n \nlimit\n gaming and dysfunctional behaviour, whilst signalling more mature and insightful performance management norms.\n&#xa0;\nNovember 2013\n&#xa0;\n&#xa0;\n&#xa0;\n&#xa0;\n&#xa0;\n&#xa0;\n&#xa0;\n&#xa0;\n&#xa0;\nReferences Barton, H. and Beynon, N. (2011) ‘Targeted Criteria Performance Improvement – An Investigation of a ‘Most Similar’ UK Police Force’. \nInternational Journal of Public Sector Management\n. 24 (4): 356-367\nBandura, A. (\n1999\n)\n ‘Moral Disengagement in th\ne \nPerpetration of Inhumanities’.\n \nPersonality and Social Psychology Review. \n3\n: 193 - \n209\nBarsky, A. (2008) Understanding the Ethical Cost of Organizational Goal-Setting: A Review and Theory Development. \nJournal of Business Ethics\n. 81: 63–81\nBevan, G. and Hood\n, C. (2006) ‘What’s Measured is What Matters: Targets and Gaming in the English Public Healthcare System’ \nPublic Administration\n 84 (3): 517-538\nBird, S. M., Cox, D., Farewell, V. T., Goldstein, H., Holt, T. and Smith, P. C. (2005) ‘Performance Indicators: \nGood, Bad and Ugly’. \nJournal of the Royal Statistical Society (A).\n 168 (1): 1-27\nCapon, N., Farley, J. and Hubert, J. (1987) \nCorporate Strategic Planning.\n New York: Columbia University Press\nChief Secretary to the Treasury. (1998a) \nModern Public Services \nfor Britain: Investing in Reform. Comprehensive Spending Review: New Public Spending Plans 1999–2002.\n London: HMSO\nChief Secretary to the Treasury. (1998b) \nPublic Services for the Future: Modernisation, Reform, Accountability. Comprehensive Spending Review\n: Public Service Agreements 1999–2002.\n London: HMSO\nDavis, R. C. (2012) \nSelected International Best Practices in Police Performance Measurement\n. Santa Monica: The RAND Centre on Quality Policing\nDe Maillard, J. and Savage, S. (2012) ‘Comparing Performance:\n The Development of Police Performance Management in France and Britain’. \nPolicing and Society: An International Journal of Research and Policy\n. 22 (4): 363-383\nDeming, W. E. (1986) \nOut of the Crisis\n. Cambridge: MIT Press\nDeming, W. E. (1994) \nThe\n New Economics for Industry, Government, Education.\n (2\nnd\n Ed) Cambridge: MIT Press\nEarley, P. C., Connolly, T., and\n Ekegren, G. (1989) ‘Goals, Strategy Development, and Task Performance: Some Limits on the Efficacy of Goal Setting’. \nJournal of Applied Psych\nology. \n74: 24 – 33\nEssex Police (2013a) \nOperation Brightshadow Reduces Burglaries by a Third\n. [Online] \nhttp://www.essex.police.uk/news_features/features_archive/2011/october/operation_brightshadow_res.aspx\n [Accessed 3rd July, 2013]\n&#xa0;\nGhobadian, A., Viney, H\n. and Redwood, J. (2009) ‘Explaining the Unintended Consequences of Public Sector Reform’. \nManagement Decision\n. 47 (10): 1514-1535\n&#xa0;\nGoldstein, H. and Spiegelhalter, D. (1996) ‘League Tables and Their Limitations: Statistical Issues in Comparisons of Instit\nutional Performance.’ \nJournal of the Royal Statistical Society\n 159 (3): 385-443\n&#xa0;\nGoodhart, C.A.E. (1975) ‘Problems of Monetary Management: The UK Experience’. \nPapers in Monetary Economics\n. (Volume I) Reserve Bank of Australia\nGuilfoyle, S. J. (2012) ‘On Target? Public Sector Performance Management: Recurrent Themes, Consequences and Questions’. \nPolicing: A Journal of Policy and Practice\n. 6 (3): 250 - 260\n&#xa0;\nGuilfoyle, S. J. (2013) \nIntelligent Policing: How Systems Thinking \nMethods Eclipse Conventional Management Practice\n. Axminster: Triarchy Press\n&#xa0;\nHome Office (1994) \nPolice and Magistrates Court Act\n. London: HMSO\n&#xa0;\nHome Office (2002) \nPolice Reform Act.\n London: HMSO\n&#xa0;\nHome Office (2005) \nPolicing Performance Assessment \nFramework. \nLondon: HMSO\nHome Office (2007) \nAssessments of Policing and Community Safety: Strategic Consultation\n.\nLondon: Home Office \n&#xa0;\nHood, C. (1991) ‘A Public Management for All Seasons?’ \nPublic Administration\n. 69 (1): 3-19\n&#xa0;\nHood, C. (1995) ‘The ‘New Pub\nlic Management’ in the 1980s: Variations on a Theme’. \nAccounting, Organizations and Society\n. 20 (2/3): 93 - 109\n&#xa0;\nHood, C. (1996) “Exploring Variations in Public Management Reform of the 1980s”. \nIn\n Bekke, H.A., Perry, J.L. and Toonen, T.A. (eds.) \nCivil Serv\nice Systems in Comparative Perspective\n. Bloomington: Indiana University Press\nHood, C. (1998)\n The Art of the State: Culture, Rhetoric and Public Management\n. Oxford: Oxford University Press\n&#xa0;\nHood, C. (2006) ‘Gaming in Targetworld: The Targets Approach to Managing British Public Services’. \nPublic Administration Review\n. 66 (4): 515-521\n&#xa0;\nHood, C. (2007) ‘Public Service Management by Numbers: Why Does it Vary? Where Has it Come From? What are the \nGaps and the Puzzles?’ \nPublic Money &amp; Management\n. 27 (2): 95-102\nHood, C. and Dixon, R. (2010) ‘The Political Payoff from Performance Target Systems: No-Brainer or No-Gainer?’  \nJournal of Public Administration and Theory. \n20 (2): 281-298\nHoque, Z, Arends, S and Alexander, R (2004) ‘Policing the Police Service - A Case Study of the Rise of “New Public Management” Within an Australian Police Service’. \nAccounting, Auditing &amp; Accountability Journal.\n 17 (1): 59-84\nJacobs, R. and Goddard, M. (20\n07) ‘How Do Performance Indicators Add Up? An Examination of Composite Indicators in Public Services.’ \nPublic Money &amp; Management\n. 27 (2): 103-110\nJames, O. (2004) ‘The UK Core Executive’s Use of Public Service Agreements as a Tool of Governance’. \nPublic Ad\nministration\n. 82 (2): 397-419\nJennings, E. T., and Haist, M. P. (2004) “Putting Performance Measurement in Context”. \nIn\n \nThe Art of Governance: Analyzing Management and Administration\n. Ingraham, P. W. and Lynn, L. E. (eds.) Washington, DC: Georgetown Univer\nsity Press\nJones, T. (2003) “The Governance and Accountability of Policing”. In: Newburn, T. (Ed) \nHandbook of Policing\n. Cullompton: Willan. pp. 603 – 627\n \n&#xa0;\nKanfer, R., \nand\n Ackerman, P. L. (1989). \n‘Motivation and C\nognitive \nA\nbilities: An \nIntegrative Aptitude\n T\nreatment \nInteraction A\npproach to \nS\nkill \nA\ncquisition\n’\n. \nJournal of Applied Psychology\n. \n74:\n \n657 – \n690\n&#xa0;\nLocke, E. A. (1968) ‘Toward a Theory of Task Motivation and Incentives\n’\n. \nOrganizational Behavior and Human Performance. 3:\n 157 \n–\n 189\n&#xa0;\nLocke, E. A., Shaw, \nK. N., S\naari, L. M., \nand Latham, G. P. (1981) ‘Goal-\nS\netting and Task Performance: 1969–1980’. \nPsychological Bulletin\n 90: 125–152\n&#xa0;\nLocke, E\n. A., Chah, D., Harrison, S., and \nLustgarten, N. (1989) \n‘Separating the Effects of Goal S\npecificity from \nGoal L\nevel\n’\n. \nOrganizational\n Behavior and Human Performance. \n43: \n270 \n–\n 287\n&#xa0;\nLocke, E. A.\n and\n Latham, G. P. (2002) \n‘\nBuilding a \nPractically Useful Theory of G\noal \nSetting and T\nask \nM\notivation\n’\n. \nAmerican Psychologist\n 57: 705 – \n717\nLocke, E. A. &amp; Latham, G. P. (2006) ‘New \nDirections in Goal-Setting Theory’. \nAssociation for Psychological Science\n. 15 (5): 265-268\nLoveday, B. (2005) ‘The Challenge of Police Reform in England and Wales’. \nPublic Money and Management\n. \n25\n(5): 275–281\nLoveday, B. (20\n06) ‘Policing Performance: The I\nmpact of Performance Measures and Targets on Police Forces in England and Wales’. \nInternational Journal of Police Science and Management\n. 8 (4): 282–293\nLoveday, B. (2008) ‘\nPerformance Management and the Decline of Leadership within Public Services in the \nUnited Kingdom’. \nPolicing.\n 2 (1): 120–130\nMackenzie, S. and Hamilton-Smith, N. (2010) ‘Measuring Police Impact on Organised Crime: Performance management and Harm Reduction’. \nPolicing: An International Journal of Police Strategies &amp; Management.\n 34 (1): 7-3\n0\nNorth Yorkshire Police (2013) \nAlmost 4,000 Fewer Victims of Crime in North Yorkshire\n. [Online] \nhttp://www.northyorkshire.police.uk/11111\n [Accessed 3rd July 2013]\n&#xa0;\nPidd, M. (2005) ‘Perversity in Public Service Performance Measurement’. \nInternational Journ\nal of Productivity and Performance Management\n. 54 (5/6): 482-493\n&#xa0;\nPollitt, C. (2002) “The New Public Management in International Perspective: An Analysis of\nImpacts and Effects”. In: McLaughlin, K., Osborne, P. and Ferlie, E. (eds.) \nNew Public\n \nManagement: Future Trends and Current Prospects. \nLondon: Routledge. pp. 274 - 292\n&#xa0;\nPollitt, C. and Bouckaert, G. (2000) \nPublic Management Reform: A Comparative Analysis\n, 2\nnd\n ed. Oxford University Press: Oxford \n&#xa0;\nReason, J. (2000) ‘Human Error: Models and M\nanagement’. \nBritish Medical Journal\n. 320, 768-770\n&#xa0;\nRothstein, R. (2008) ‘Holding Accountability to Account’. \nNational Center on Performance Incentives\n. Working Paper 2008 – 04. Nashville: Vanderbilt\nSchweitzer, M. E., Ordonez, L., and Douma\n, B. (2004) ‘Goal Setting as a Motivator of Unethical Behaviour’. \nAcademy of Management Journa\nl. 47 (3): 422 - 432\nSmith, P.\n \n(1990) ‘The Use of Performance Indicators in the Public Sector’.\n Journal of the Royal Statistical Society.\n 153 (1) pp.53-72\n&#xa0;\nSmith,\n P. (1995) ‘On the Unintended Consequences of Publishing Performance Data in the Public Sector’. \nInternational Journal of Public Administration\n. 18 (2 &amp; 3): 277–310\n&#xa0;\nSpitzer, D. R. (2007) \nTransforming Performance Measurement: Rethinking the Way We Measure \nand Drive Organizational Success\n. New York: Amacom\n&#xa0;\n&#xa0;\n&#xa0;\n&#xa0;\n&#xa0;\n&#xa0;\n&#xa0;\n&#xa0;\n&#xa0;\n"