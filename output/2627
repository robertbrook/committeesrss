&#xa0;
defaultWritten evidence submitted by the Open Rights Groupdefault [OLS0074]default&#xa0;
default&#xa0;
defaultWe welcome the attention that the Committee is devoting to looking at these important issues and appreciate the opportunity to offer our views. 
default&#xa0;
defaultThe areas covered by the Inquiry have been the subject of quite intense, heated and not always helpful or cons
defaulttructive debate this summer.  We hope that this Inquiry provides an opportunity for a calm and considered look at these difficult issues.
default&#xa0;
defaultOpen Rights Group 
defaulthave
default done a significant amount of work on how Internet filtering works over the past few years. Tha
defaultt has included:
default&#xa0;
default&#xa0;
defaultAs an organisation focused on human rights and civil liberties in the digital age, we believe it is possible to reconcile the idea that the Internet can create greater opportunities for exercising the right to freedom of expre
defaultssion with a desire to tackle the problems and dangers young people now face online. 
default&#xa0;
defaultWe do not see these as mutually exclusive aims. But we also believe that a simplistic 'restrictions' based approach to child safety will: fail on its own terms due large
defaultly to the limitations of filtering technology; ignore the wider social issues that young people face; and lead to overly restrictive content practices that reduce the usefulness of the Internet for everybody.
default&#xa0;default1. How best to protect minors from defaultaccessing adult contentdefault&#xa0;
defaultIn summary, some of our key recommendations to the Government are: 
default&#xa0;
default&#xa0;
defaultWe 
defaultbelieve that the Department for Education response to their consultation in December 2012 arrived at
default a reasonable position – that the Government should help parents make their own decisions about what is best for their household. It has been disappointing to see the Government somewhat turn away from this and effectively mandate default-on filtering. 
default&#xa0;
default&#xa0;
defaultChallenging the 'one click to safety' approach
default&#xa0;
defaultIn his summer speech on filtering and child protection the Prime Minister promised 'no more hassle of downloading filters for every device, just one click protection. One click to protect your whole home and 
defaultto keep your children safe
default..
default' 
default&#xa0;
defaultWe believe this is unhelpful and misleading, and runs against the advice of the previous Byron and Bailey reviews of online safety undertaken for the Government.
default&#xa0;
defaultThere is no switch that will keep children and young people 
defaultsafe. If we encourage parents to believe that there is, too many will assume their job is done when they press it. That is to ignore the limitations of the filtering services and the broader issues and pressures that children and young people face online. 
default&#xa0;
defaultStart with good evidence
default&#xa0;
defaultToo often anecdotes, 
defaultunsourced
default figures or insufficiently robust evidence has been used by those in the debate about online safety. We would urge the Committee to base its findings in the best available evidence – and there is pl
defaultenty of good quality work, for example from the aforementioned EU Kids Online project run by Professor Sonia Livingstone - and also to be rigorous in questioning the evidence presented to it.   
default&#xa0;
defaultAvoiding default-on filters and 
defaultendorse
default active choice
default&#xa0;
defaultThere
default is a risk that default internet filtering will move decisions about what is appropriate for families and households further out of parents' hands. The Government should instead promote an 'active choice' model that encourages parents to make their own dec
defaultisions about what is appropriate and what tools to use.
default&#xa0;
defaultWe believe the available evidence (for example, from 
defaultthe EU Kids Online project
default) does not support an approach focused simply or primarily on filtering restrictions, and certainly not a 
defaultdefault 'on' Internet filter. 
default&#xa0;
defaultFiltering services are error-prone
default&#xa0;
defaultWe know that filtering systems often, through error or overreach, lead to the blocking of legal and legitimate content. This is a 
defaultbyproduct
default of trying 
defaultcategorise and filter
default such a massive v
defaultolume of content. We would point here, for example, to our work looking at mobile Internet filtering products (which is noted in the introduction). We found amongst others, political blogs, political campaigns, community websites, gay news sites, church gr
defaultoups and technology news sites blocked by accident by mobile networks. 
default&#xa0;
defaultRather than looking at 
defaultwhether
default this is a problem, policy makers should be asking how to take this fact into account.  We are concerned that some vocal supporters of default filtering 
defaultplay down concerns about mistaken blocking, seeing them as just pedantic quibbles
default.
default&#xa0;
defaultThere are a number of damaging consequences of ignoring this problem. 
default&#xa0;
defaultFirst, website owners find it harder to figure out if their site is blocked by one of the filters. 
defaultThis is not an easy task, as most operators of blocking services do not offer an easy way to check URLs (O2 is a notable exception – see their URL checker
default). This problem grows when a website owner is faced with a number of blocking services across the var
defaultious ISPs and service providers, and grows further when they face having to look at other country's policies. If we pretend that over-blocking is not a problem, there will be no effort to improve matters for affected website operators. 
default&#xa0;
defaultSecond, our experi
defaultence of talking to affected website owners is that they find it hard to get their site unblocked when it is mistakenly categorised as '
defaultblockable
default' by a filtering service. 
default&#xa0;
defaultService providers operating filtering services should be asked how they have assesse
defaultd the risks of over-blocking and whether they have taken steps to 
defaultensue
default their deployment of filtering tries to address this. They should explain how they will ensure website owners are able to report mistakes and get problems fixed.  And service providers 
defaultshould ensure that website owners are able to easily check whether their site has been categorised by the filtering system. 
default&#xa0;
defaultWe would like to highlight two damaging consequences of over-blocking – on access to information, and on the economy.
default&#xa0;
defaultAccess to 
defaultinformation
default&#xa0;
defaultFirst, it would be worrying if sites blocked by accident or through overly broad 
defaultcateogries
default are considered collateral damage of filtering services, as this would be to deny young people access to information at the very moment when it is most 
defaultimportant to be helping them satisfy their curiosity and interests. 
default&#xa0;
defaultFiltering can lead to children, young people, and adults being denied access to legitimate and age-appropriate information and resources such as sexual health information and advice.
default&#xa0;
defaultFi
defaultltering that covers different age ranges and / a broadly defined set of ‘adult’ content can deny young people access to material appropriate to their development and needs. In a paper to the EU Kids Online conference in 2011, Tim Davies, 
defaultSangeet
default 
defaultBhullar
default an
defaultd Terri 
defaultDowty
default argued that filtering can therefore restrict young people’s rights in the name of protecting them from risk – specifically “rights to freedom of expression and access to information across frontiers (Article 13, 17), rights to freedom of asso
defaultciation (Article 14), rights to preparation for responsible life in a free society (Article 29) and rights to protection of privacy (Article 16)”. They argue that:
default&#xa0;
default“
default...these broader rights are frequently neglected - with young people’s access to 
defaultinformation on key topics of health, politics and sexuality limited by Internet filtering - and with a lack of critical formal and informal education supporting young people to gain the skills to live creative and responsible lives in increasingly digitall
defaulty mediated societies.”
default              
defaultAn unintended economic impact
default&#xa0;
defaultSecond, to give a specific example, we heard from the owner of an online gift shop that their site had been blocked by Orange's Safeguard system over Christmas last year. The site sold engraved ciga
defaultrette lighters, and so we assumed the filters had mistakenly categorised the site under its 'tobacco' category. Despite reporting the issue in early December it took until January to get the problem sorted and the site removed from the block list
default. 
default&#xa0;
defaultA lar
defaultger business may have been able to pressure for a resolution sooner – we see no good reason that smaller businesses should be inhibited in their efforts to reach consumers online in ways larger businesses are not.
default&#xa0;
defaultTo build systems in which less establish
defaulted businesses or organisations are hampered in this way undermines one of the core benefits that the Internet offers for economic and social innovation.
default&#xa0;
defaultDevice based filters are preferable to network level filters
default&#xa0;
defaultWe urge the Committee to look seriously 
defaultat the relative merits of network-level and device-based filters, across different contexts. We have previously written about some of the benefits and problems of each, and refer the Committee to this previous briefing
default.
default&#xa0;
defaultA healthy market for parental 
defaultcontrols is developing; everything proposed regarding filtering technology is available to parents already. Mandating network level filtering would amount to an intervention that could disrupt an emerging market for Internet access tools, whilst imposing s
defaultignificant costs on Internet Service Providers. 
default&#xa0;
defaultThe Government's role should be to support this variety of tools and services by working with industry to ensure these are easily available and that parents understand how to use them.
default&#xa0;
defaultFiltering services b
defaultlock more than pornography
default&#xa0;
defaultSo far the debate has tended to focus on how filters should block 'pornography' or even more specifically 'hard core pornography'. Yet most if not all filtering systems are set up to block a range of categories of content extend
defaulting beyond adult sexual content. We urge the Committee to look at the variety of content that filtering systems block, how those categories are developed, who considers them to be '18 rated', and what sort of sites those offering filtering think should fal
defaultl under those categories. 
default&#xa0;
defaultDifferent categories of material require different approaches
default&#xa0;
defaultToo often in the recent debate, a variety of different categories of material have been confused and muddled together. That has led to a confused discussion about th
defaulte appropriate way to deal with such a variety of material.
default&#xa0;
defaultFor example, child abuse images are illegal and dealt with by the Internet Watch Foundation. Other types of unlawful content may be subject to powers that can lead to content being taken down. 
default&#xa0;
defaultO
defaultther material that is considered merely unsuitable for people of different ages however – and thus relevant when talking about home Internet filters - will involve more subjective judgments. Those will of course likely vary across households or value syste
defaultms. 
defaultWhen talking about legal material, there is no easy way to define a category of unsuitable content that young people or children should be protected from. This is especially problematic when considering that filtering can happen in a variety of setti
defaultngs (libraries or shops and cafes or schools or homes or on devices taken across all of them), for a variety of age groups, and for people with a variety of values and beliefs.
default&#xa0;
defaultWe urge the Committee to keep a clear head about the very different types of m
defaultaterial at issue and how each requires a different approach when considering how to create safer experiences for young people online across contexts. 
default&#xa0;
defaultEnsuring that policy makers are asking the right questions
default&#xa0;
defaultWe have not been convinced that in pushing t
defaulthe filtering policies forward, policy makers this year have examined the most important practical questions closely enough. 
default&#xa0;
defaultAs a result, we have asked 20 questions of ISPs (also noted in the introduction), which cover some of the most significant practic
defaultal issues with implementation of filtering services including privacy, how choices will be framed and how mistakes will be dealt with. We will submit answers when we receive them. We urge the Committee to look at these questions and consider the extent to 
defaultwhich ISPs have addressed them adequately
default. 
default&#xa0;
defaultImprove sexual health and relationships education
default&#xa0;
defaultWe support the work of academics such as Professor Andy 
defaultPhippen
default, who in his research engages with young people in schools 
defaultto talk about the pressures and problems they face in a world in which 'digital' and 'real' life are not distinct. 
default&#xa0;
defaultWe support the suggestion that these issues are social problems facilitated by technology that cannot be fixed through technological fixes. 
defaultWe also support the recommendation that we should endeavour to create an environment in which young people feel safe
default and supported in talking about 
defaultthe problems they face. One aspect of this is to look at improving sexual health and relationship education. So we urge the Committee to look carefully at this context in which children and young people experience problemati
defaultc material online, rather than just at the limited tools available to try and limit access to some of it. 
default&#xa0;
default&#xa0;
default2. defaultFiltering out extremist material, including images of child abuse and material intended to promote terrorism or other acts of violencedefault&#xa0;
defaultWe would
default firstly echo our previous comments. For example, as noted above, it is important for policy makers to recognise that we are talking about a variety of different categories of material. We should not assume that it is easy to define what content to filter 
defaultout for which people or age group, and we should keep illegal and merely objectionable material distinct. 
default&#xa0;
defaultOur comments above about the subjective judgments involved in deciding what content to filter are particularly relevant when looking at a broader ra
defaultnge of content. Words like 'violent', 'extreme', 'upsetting' or 'offensive' will have different meanings to people of different ages, beliefs and will this will vary across different settings. 
default&#xa0;
defaultIf policy makers do push for an overly simple approach of spe
defaultcifying broad categories of legal but objectionable content to be filtered in a particular places, it is important to remember that this is not 
defaultstopping
default these subjective judgement being made. Instead, those judgments are being made by a combination of thos
defaulte in charge of the provision of Internet access in that context (for example, perhaps a building maintenance service), the Internet service providers they use and the filtering service that ISP uses. Each will have their own attitude towards the 
defaultblockable
default 
defaultcategories and what material should fall within them.  Where these systems are opaque, as they often are, it just becomes harder to understand what decisions about access have been made. 
default&#xa0;
default3. Preventing abusive or threatening comments on social media.default&#xa0;defaultWe
default believe that an important aspect of dealing with this is to create a support system for young people with clear routes for them to report problems and find help.
default&#xa0;
defaultOnce again, it is important to distinguish between different types of behaviour, such as 
defaultoffensiveness, abusiveness or threats, which will require different approaches.
default&#xa0;
defaultWe also urge the Committee to look carefully at the issue of anonymity and 
defaultrelatedly
default 
defaultpseudonymity
default. It is too easy to assume that tackling anonymity online is a simple solution
default to abusiveness. 
default&#xa0;
defaultIn fact, people are usually not truly 'anonymous' when they are online. People leave all sorts of information that can identify them.  It is sometimes possible to use this information to identify somebody with varying levels of confidenc
defaulte – even if the person posts messages as an 'anonymous' or 'pseudonymous' user. For example an ISP may try to 'match' an IP address with one of their subscribers. There are various legal powers that in some 
defaultcircumstance,
default require Internet companies to discl
defaultose this data, and which permit the use of it in various contexts for the purposes of trying to identify a user. 
default&#xa0;
defaultFurther, anonymity in fact serves many positive purposes in a variety of circumstances. 
defaultFor further 
defaultinformation, please see our short introdu
defaultction to anonymity online, available from our website
default. 
default&#xa0;
defaultSeptember 2013
default&#xa0;
default              
defaulthttps://www.openrightsgroup.org/ourwork/reports/mobile-internet-censorship:-whats-happening-and-what-we-can-do-about-it
default 
default              
defaulthttps://www.openrightsgroup.org/ourwork/reports/response-to-dfe-consultation-on-parental-controls
default              
defaulthttps://www.openrightsgroup.org/ourwork/letters/open-letter-to-the-prime-minister-regarding-parental-internet-controls
default 
default              
defaulthttps://www.openrightsgroup.org/ourwork/reports/parental-controls-and-internet-filtering-fact-sheet
default              
defaulthttps://www.openrightsgroup.org/ourwork/letters/culture-sec-content-restrictions
default 
default              
defaulthttps://www.openrightsgroup.org/blog/20
default13/isp-filtering-qs
default 
default              
defaulthttps://www.gov.uk/government/speeches/the-internet-and-pornography-prime-minister-calls-for-action
default 
default              
defaulthttp://www2.lse.ac.uk/media@lse/research/EUKidsOnline/EU%20Kids%20III/Reports/ParentalMediation.pdf
default 
default              
defaulthttps://www.openrightsgroup.org/blog/2013/website-filtering-problems-are-a-load-of-cock
default 
default              
defaultht
defaulttp://urlchecker.o2.co.uk/urlcheck.aspx
default 
default              
defaultSee Tim Davies, 
defaultSangeet
default 
defaultBhullar
default, and Terri 
defaultDowty
default, “Rethinking responses to children and young people’s online lives”, September 2011, 
defaulthttp://www2.lse.ac.uk/media@lse/research/%20EUKidsOnline/Conference%202011/Davies.pdf
default 
default              
defaulthttps://www.openrig
defaulthtsgroup.org/blog/2013/online-gift-shop-blocked-by-mobile-networks
default 
default              
defaulthttp://www.openrightsgroup.org/assets/files/files/pdfs/Net%20Filtering%20Brie
defaultf.pdf
default 
default              
defaulthttps://www.openrightsgroup.org/blog/2013/isp-filtering-qs
default              
defaulthttp://www.openrightsgroup.org/assets/files/pdfs/ORG%20anonymity%20introduct
defaultion.pdf
default 
default