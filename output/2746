&#xa0;
[normal]Written evidence submitted by the C[bold]hildren’s [bold]C[bold]harities’ [bold]C[bold]oalition on [bold]I[bold]nternet [bold]S[bold]afety[bold]&#xa0;
[normal]Thank you for giving us the opportunity to submit evidence to your Committee’s enquiry into:
[normal]Our fuller views are set out in the following pages and summarised as follows:
[normal]&#xa0;
[normal]&#xa0;
[normal]&#xa0;
[normal]&#xa0;
[normal]&#xa0;
[normal]&#xa0;
[normal]&#xa0;
[normal]&#xa0;
[normal]&#xa0;
[normal]&#xa0;
[normal]&#xa0;[bold]1.
[normal]&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; 
[normal]With the spread of 
[normal]WiFi
[normal] and laptops, tablets or other mobile devices which are internet enabled it is wholly unrealistic to expect parents, t
[normal]eachers and carers to be able to supervise everything their children do when they go online. 
[normal]&#xa0;
[normal]2.
[normal]&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; 
[normal]Protecting children from accessing adult content on the internet can be done most effectively through educating and empowering children to look after themselves although with very young children there are obvious limitations to this approach.
[normal] Filtering and blocking programmes can play an important supplemental role underpinning parental guidance and good practice. Such software may be especially useful supporting younger or particular groups of vulnerable children.
[normal]&#xa0;
[normal]3.
[normal]&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; 
[normal]Every internet enabled device or internet based service sold or supplied into the consumer market and likely to be owned or used by children or young people should, by default, come with filtering and blocking software preinstalled and operational to provide protection against exposure to adult content. An age-verified adult ought to be able to modify the preinstalled protective programmes’ settings or abandon them altogether.
[normal]&#xa0;
[normal]4.
[normal]&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; 
[normal]Filtering and blocking software is still far from perfect but it continues to improve. However, any and all
[normal] technically-based safety measures should only ever be seen as an adjunct to and not as a replacement for educational and awareness initiatives. Parents and children need to understand the nature of potential online hazards and appreciate both what safety software can do and what its limitations are.
[normal]&#xa0;
[normal]5.
[normal]&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; 
[normal]The decision in the case of R v Perrin is honoured more in the breach than in the observance although it is recognised that most if not all of the offending web sites are owned by publishers based overseas. 
[normal]&#xa0;
[normal]6.
[normal]&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; 
[normal]The police should be more vigorous in applying R v Perrin, perhaps seeking to extradite overseas web site owners who make no attempt to shield minors from adult content. 
[normal]&#xa0;
[normal]7.
[normal]&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; 
[normal]Nominet
[normal] should make compliance with R v Perrin a condition of operating a .
[normal]uk
[normal] domain name e.g. if a site is to publish pornography the operator must give a binding undertaking to put an effective age verification process in place before the site goes live or within a reasonable timeframe. It should be noted that the UK’s online gambling industry has used age verification with great success. 
[normal]&#xa0;
[normal]8.
[normal]&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; 
[normal]UK-based web hosting companies should ensure publishers making pornography available within the UK have an effective age verification process in place. 
[normal]&#xa0;
[normal]9.
[normal]&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; 
[normal]CHIS supports ATVOD’s proposal for banks and credit card companies to refuse to process payments to any pornography sites that do not have an effective age verification process in place.
[normal]&#xa0;
[normal]10.
[normal]&#xa0;&#xa0; 
[normal]CHIS congratulates the UK’s mobile phone networks for sustaining their policy of, by default, putting adult content behind a bar which can only be lifted by the user completing an age verification process. CHIS welcomes the recent engagement of the BBFC to oversee the administration of this scheme including setting standards governing which content should go behind the adult bar.  
[normal]&#xa0;
[normal]11.
[normal]&#xa0;&#xa0; 
[normal]CHIS also commends the UK’s largest 
[normal]WiFi
[normal] companies for deciding that, when they are asked to provide 
[normal]WiFi
[normal] access in a public space where children and young people will normally be present, by default they will put pornographic content behind an (immovable) adult bar. Several of the 
[normal]WiFi
[normal] companies have already implemented this decision. 
[normal]CHIS calls
[normal] on the remainder to make a statement making clear when they will have done the same. Smaller 
[normal]WiFi
[normal] suppliers should follow a similar path within a reasonable timeframe. 
[normal]&#xa0;
[normal]12.
[normal]&#xa0;&#xa0; 
[normal]The BBFC should be encouraged to develop a 
[normal]kitemark
[normal] scheme and associated standards in respect of public 
[normal]WiFi
[normal] and 
[normal]WiFi
[normal] providers ought to adopt and advertise their compliance with it.  
[normal]&#xa0;
[normal]13.
[normal]&#xa0;&#xa0; 
[normal]A child should not be prevented from accessing certain types of adult content while they are using their mobile phone company’s network only to find they are able to access identical material via the same device simply by switching to 
[normal]WiFi
[normal]. There needs to be a high degree of consistency as between the standards set by mobile operators and those being applied by 
[normal]WiFi
[normal] providers. The BBFC would be well placed to help establish such consistency and also ensure transparency in relation to the content standards and processes being used. 
[normal]&#xa0;
[normal]14.
[normal]&#xa0;&#xa0; 
[normal]CHIS welcomes the announcement by the UK’s major ISPs of their intention to upgrade the level of protection against adult content offered to new customers and their support for the “one click” approach. The ISPs have pledged to have their new offerings in place by the end of 2013. Existing customers will be put in an equivalent position by the end of 2014.
[normal]&#xa0;
[normal]15.
[normal]&#xa0;&#xa0; 
[normal]Since none of the ISPs have yet disclosed what their final offerings will be CHIS does not propose to comment further at this stage other than to say CHIS believes ISPs should, as closely as possible, implement a system similar to that which exists on the mobile networks.
[normal]&#xa0;
[normal]16.
[normal]&#xa0;&#xa0; 
[normal]The logic of this approach points towards the need for individual accounts for each household member. By default adult content would therefore be inaccessible to the whole household and remain inaccessible unless and until a responsible adult has authorised a change, account by account. The worry otherwise is that in households with people of widely differing ages it will prove unworkable for everyone’s internet access to be configured to be suitable only for a child. There are routers on the market which have been built precisely to allow for this type of arrangement. Alternatively it could be achieved on the network.
[normal]&#xa0;
[normal]17.
[normal]&#xa0;&#xa0; 
[normal]The BBFC once more could play a useful role in helping ISPs roll out a solution while providing consistency with other platforms and transparency as to the processes.
[normal]&#xa0;
[normal]18.
[normal]&#xa0;&#xa0; 
[normal]In relation to adult content not directly accessed from the internet but obtained in other ways e.g. via Bluetooth, USB sticks, memory card exchanges, emails, disc swaps or downloads CHIS looks to the wider deployment of technical tools to deter or deflect such activities and thereby help protect minors from age inappropriate content.
[normal]&#xa0;
[normal]&#xa0;[bold]19.
[normal]&#xa0;&#xa0; 
[normal]The UK has done extremely well in more or less eliminating the hosting of child abuse images on UK-based web servers. The deployment of the IWF’s 
[normal]url
[normal] blocking list has also been important in limiting web access to that kind of material. Images found in Newsgroups are swiftly dealt with. However, whilst it is important to retain a strong focus on the web and Newsgroups, technology has moved on and we are now a long way from coping with more modern manifestations of the problem.
[normal]&#xa0;
[normal]20.
[normal]&#xa0;&#xa0; 
[normal]In 2012 the NSPCC issued FOI requests to every local police force in England and Wales asking them to state how many child abuse images they had seized in arrests made in the two years ending April, 2012. Within the NSPCC’s timeframe only five forces replied but it 
[normal]emerged
[normal] that between them they had seized over 26 million. On one calculation that would imply that over 300 million illegal images may have been seized by all forces over the same period. Numbers like these are unprecedented and while numbers do not by any means tell the full story, they most certainly tell 
[normal]a 
[normal]story.
[normal]&#xa0;
[normal]21.
[normal]&#xa0;&#xa0; 
[normal]On ITN News on 28
[normal]th
[normal] May, 2013, Peter Davies, the Head of CEOP, 
[normal]acknowledged
[normal] that the UK police had identified between 50,000 and 60,000 individuals who appeared to have been exchanging or downloading child abuse images, principally over Peer2Peer networks. Davies said the police do not have the capacity to arrest all of these people although he said 
[normal]“I wish we could”.
[normal] 
[normal]&#xa0;
[normal]22.
[normal]&#xa0;&#xa0; 
[normal]In no year since records began, including at the height of Operation Ore, has UK policing arrested more than 2,500 individuals for child abuse image related offences. Thus, even if there were no new offences from now on, and assuming the maximum rate of arrests was sustained year on year, conservatively the last person off the current list would not be picked up before 2032.  This has worrying implications both for the abused children depicted in the images and children who may yet become victims of individuals whom the police have identified as being engaged in downloading. 
[normal]&#xa0;
[normal]23.
[normal]&#xa0;&#xa0; 
[normal]The technology has outstripped the current capacity of UK law enforcement to cope with the volumes of images in circulation and with the numbers of offenders involved in downloading or distributing them.  Most police forces around the world are in the same position.
[normal]&#xa0;
[normal]24.
[normal]&#xa0;&#xa0; 
[normal]However, even if the UK was living through times of super abundance, as opposed to times of austerity, it is hard to imagine how we would ever be able to manage criminal behaviour on the sort of scale indicated. Society therefore has a stark choice. Either we settle back and accept that substantial numbers of people living among us are routinely accessing child abuse images, that it has become, so to speak, part of the background music of 21
[normal]st
[normal] Century Britain, or we look for new and better ways to enlist the internet industry’s support in finding technical measures to address the problem. 
[normal]CHIS does
[normal] not think anyone in a position of responsibility is ready to go with the first option. We strongly favour the second.
[normal]&#xa0;
[normal]25.
[normal]&#xa0;&#xa0; 
[normal]There is no single measure which will get rid of child abuse images from the internet. A range of tactics are needed. CHIS puts forward the following for consideration:
[normal]&#xa0;
[normal]&#xa0;
[normal]&#xa0;[bold]26.
[normal]&#xa0;&#xa0; 
[normal]Clearly this is an area where educating people about the importance of behaving in a civilized and responsible way when using social media, and explaining the potential consequences of not doing so, will have an important part to play in 
[normal]combatting
[normal] some of the worst excesses which have attracted the media’s attention in the recent past.
[normal]&#xa0;
[normal]27.
[normal]&#xa0;&#xa0; 
[normal]Peer-based support networks which develop a sense of social solidarity among the users of social media, which encourage people to intervene to support someone being bullied or victimized and to bring an end to another person’s bad behaviour are the sorts of initiatives which all social media sites should support. 
[normal]&#xa0;
[normal]28.
[normal]&#xa0;&#xa0; 
[normal]However, unless social media services decide to pre-moderate every post, be it of images or text, it is difficult to imagine how they could ever “prevent” abusive or threatening comments being made.
[normal]&#xa0;
[normal]29.
[normal]&#xa0;&#xa0; 
[normal]Many online companies, including some small or niche social media sites, do pre-moderate everything or almost everything that goes up. They do so for a range of reasons at least one of which is a concern for their own reputation but also they are keen to minimise any potential legal liability for libel. In some instances a concern to protect younger users from possibly harmful self-disclosures has been a motivation for using pre-moderation. There may be some situations where pre-moderation is essential e.g. on services specifically directed at young or vulnerable children.
[normal]&#xa0;
[normal]30.
[normal]&#xa0;&#xa0; 
[normal]That said, the scale on which sites like Twitter and 
[normal]Facebook
[normal] operate probably renders pre-moderation impracticable even if it was thought desirable. However, it is a myth to assume that all pre-moderation systems inevitably slow down chat or interactive environments to a point where it is impossible to maintain a sense of real time or swift action.
[normal]&#xa0;
[normal]31.
[normal]&#xa0;&#xa0; 
[normal]Nonetheless technological solutions are available which can analyse text streams and help identify “hot spots” connected with bullying or other types of abusive behaviour including grooming, some of which may lead on to the creation of child abuse images or sexual assaults of a different kind. The software ought to flag up potential problem areas to human moderators who should be working 24/7 and employed in sufficient numbers to be able to intervene rapidly if necessary. Measures of this type should be in place from the start of a site’s operations. Companies should not wait for a tragedy before doing the right thing. Someone in the company should sign off confirming that full consideration has been given to all child safety 
[normal]aspects before any new online product or service is launched, especially on to the so-called “free” internet where it is known children and young people will have ready access.
[normal]&#xa0;
[normal]32.
[normal]&#xa0;&#xa0; 
[normal]There seems little doubt that the ability to hide behind an apparent cloak of anonymity, in particular the ability to manufacture an entirely bogus or opaque online identity which is then used on social media sites, lies at the root of much of the problem, even on sites which ostensibly specify a “real names” policy.
[normal]&#xa0;
[normal]33.
[normal]&#xa0;&#xa0; 
[normal]In principle CHIS has no problem with individuals signing in as “Donald Duck III” or “Diana 
[normal]Dors
[normal]”. There may be many situations where not using your real name will be positively helpful or beneficial. What matters is traceability. In an environment where everyone’s real world identify had been robustly verified the log in they used would be less important but one would expect people’s behaviour to improve because they would know that if they crossed particular lines police or the civil courts would be able to identify and locate them extremely quickly if required.
[normal]&#xa0;
[normal]34.
[normal]&#xa0;&#xa0; 
[normal]CHIS accepts
[normal] that the implications of the view expressed here are major and radical. For that reason CHIS would like separate and specific detailed consideration to be given to the issue of online anonymity, perhaps focusing specifically on social media sites which are known to be particularly popular with children and young people. 
[normal]&#xa0;
[normal]35.
[normal]&#xa0;&#xa0; 
[normal]CHIS has
[normal] no desire to make it harder for whistleblowers to continue to perform an important public service. Nor does CHIS wish to require political dissidents or persons dealing with sensitive issues to disclose their true identities before they can log on to any online service. 
[normal]&#xa0;
[normal]36.
[normal]&#xa0;&#xa0; 
[normal]However, equally, CHIS finds it difficult to accept this is a zero sum game where advances in online child protection are forever seen as being made at the price of imperilling political dissent, 
[normal]whistleblowing
[normal] or the position of others with a genuine
[normal] need for anonymity.  
[normal]&#xa0;
[normal]37.
[normal]&#xa0;&#xa0; 
[normal]The internet is now many different things to many different people. Perhaps it is simply expecting too much for all of it to be governed by a single perspective, a single set of principles or priorities. In other words not all social media sites or online services need to be governed by the same rules. Perhaps those that are used by large numbers of children and young people could reasonably be expected to conform to different standards. 
[normal]&#xa0;
[normal]September 2013
[normal]&#xa0;
[normal]