&#xa0;
[normal]Written evidence submitted by [bold]BeatBullying[bold] [OLS0072][bold]&#xa0;
[normal]&#xa0;
[normal]1.1
[normal]&#xa0;&#xa0; 
[normal]BeatBullying is the UK's leading bullying prevention charity, creating a world where bullying, violence and harassment are unacceptable. BeatBullying empowers people to understand, recognise, and say no to bullying and cyberbullying, violence and harassment, by giving them the tools to transform their lives and the lives of their peers. 
[normal]&#xa0;[bold]1.2
[normal]&#xa0;&#xa0; 
[normal] [bold]As an organisation with children’s and young people’s safety (both online and offline) at its heart,
[normal] BeatBullying’s online programmes have embedded user protection mechanisms at several levels from the beginning. Users have access to all the functions of a social networking site
[normal]—
[normal]email-style private messaging, instant messaging chat in real time, a customisable profile page, the chance to upload content including blogs, and a 
[normal]chatroom
[normal]—
[normal] but with the safety and wellbeing of its users built in as a core priority across every aspect. The BeatBullying site is fully moderated for language and content both by software and by human moderators; all content is checked and approved before being uploaded; the site has clearly stated rules for safety and behaviour which users are expected to follow, with a system of sanctions for breaking them; staff and moderators can eject, ban and block any user whose behaviour is unacceptable; there are extensive reporting systems in place both for users to report issues such as bullying by others on the site and for staff to share information, including the reporting of users who appear to be adults. BeatBullying.org is the only e-mentoring and social networking site to be endorsed by CEOP.  We strongly believe that our approach to online safety must be adopted by all internet providers if children and young people are to be safe online
[normal].[bold]  
[normal]&#xa0;
[normal]2[bold]&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; 
[normal]Summary [bold]&#xa0;
[normal]2.1
[normal]&#xa0;&#xa0; 
[normal]BeatBullying’s online programmes all utilize a combination of approaches to keeping children and young people safe online, of which the technical safeguards outlined above are a fundamental part. However, these cannot be considered in isolation from the other aspects of our work
[normal]—
[normal]education, support, attitude and behaviour change, and empowerment
[normal]—
[normal]which are just as fundamental. 
[normal]&#xa0;
[normal]2.2
[normal]&#xa0;&#xa0; 
[normal]BeatBullying is completely in agreement with the principle of preselecting to block genuinely harmful content such as pornography but could not endorse any system that might deny access to legitimate information, advice and support around sensitive issues due to over-zealous and inadequately nuanced filtering.
[normal]&#xa0;
[normal]2.3
[normal]&#xa0;&#xa0; 
[normal]The most useful ‘parental control’ is parental responsibility and, inseparable from this, the commitment to developing their children’s own sense of responsibility as they grow up.
[normal]&#xa0;
[normal]2.4
[normal]&#xa0;&#xa0; 
[normal]Blocks and filters can only block and filter; they cannot educate children about how to deal with the kind of content and behaviour they might encounter online, how to manage their own behaviour responsibly or why certain material is harmful.
[normal]&#xa0;
[normal]2.5
[normal]&#xa0;&#xa0; 
[normal]Everyone involved with children’s and young people’s use of the internet
[normal]—
[normal]parents, schools, service providers, organisations and children themselves
[normal]—
[normal]has a shared responsibility for online safety.  That is why in April 2013 BeatBullying launched a campaign for better anti-bullying protections called Ayden’s Law
[normal]. The campaign calls for a national strategy to tackle 
[normal]cyberbullying and would set out how the voluntary and community sector, parents and schools would be equipped to (a) protect the children in their care from harm online and (b) educate and equip children about internet safety and responsible digital citizenship so that they understand the issues for themselves.  
[normal]&#xa0;
[normal]2.6
[normal]&#xa0;&#xa0; 
[normal]Any approach to online safety must ultimately be about shaping attitudes and changing behaviors as much as it is about teaching techniques for staying safe or for anything else.
[normal]&#xa0;[bold]3[bold]&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; 
[normal]How best to protect minors from accessing adult content[bold]&#xa0;
[normal]3.1Findings from our recent survey of children and parents
[normal] show that the majority of parents and children (78% and 48%) agree that parents should mainly be responsible for controlling what children access online with two thirds (66%) of parents feeling confident enough to advise their children where to go online. 
[normal]&#xa0;
[normal]3.2
[normal]              
[normal]Whilst we understand that parents have a responsibility to protect minors from accessing adult content online, we would argue that parental controls are only part of the wider issue of responsibility. The most useful ‘parental control’ is parental responsibility and, inseparable from this, the commitment to developing their children’s own sense of responsibility as they grow up.
[normal] It is imperative that children and young people are encouraged to take appropriate responsibility for themselves and their own behaviour increasingly, so as they grow up but beginning in small ways at an early age. In this way, while parents and other adults will still be highly involved, children can be supported to grow up with the idea of responsibility as something integral to, rather than entirely outside of, themselves. Our peer mentoring system works on the premise that children and young people can and do rise to the challenge of appropriate responsibility, properly supported at every stage by older peers and trained adults. Of course online safety cannot be the responsibility of children in isolation, but neither can it be the responsibility of parents alone. 
[normal]&#xa0;
[normal]3.4
[normal]              
[normal]Over half (57%) of the 11 – 18 year old respondents surveyed in 2012
[normal] told us their parents talk to them about online safety and what they should or should not look at on the internet as a way to keep them safe online. As the largest category of response this indicates that among our respondents a majority of parents are actively engaged in their children’s use of online technology. Over a quarter (27%) say that their parents do not use any methods (technological or otherwise) of keeping them safe online and a fifth (20%) say that they use technological filters. 
[normal]Almost the same proportion (17%) report that their parents encourage them to use websites about internet safety, and 12% say that their parents sit with them while they are online and watch what they do.
[normal] Further written responses included ‘offering non-intrusive advice’ and ‘trust’, which illustrate an aspect of the online safety debate which is often overlooked: the relationship between parent and child and its bearing on the development of trustworthiness. This reinforces the argument for increased education for children/young people and parents, ideally helping them to develop a continued dialogue about the use of the internet.   
[normal]&#xa0;
[normal]3.6 Under 18 is a broad category; while we agree that there is some material that no-one under this age should be able to access, there are also many grey areas: some things that would be completely off-limits to a primary-school child might be fine for a 14 year-old. Just as in the offline world, older teenagers are expected to have much more independence than young children; what would be appropriate for a 7 year-old and for a 17 year-old to view or engage with online are going to be very different. CHIS (Children’s Charities Coalition on Internet Safety) suggests the possibility of allowing different user accounts to be set up for users of different ages in a single household, via routers that are built for this specific purpose; BeatBullying supports this, with the caveat that age verification systems need to be more advanced in order to ensure that it works as it should.      
[normal]&#xa0;
[normal]4[bold]&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; 
[normal]Filtering out extremist material, including images of child abuse and material intended to promote terrorism or other acts of violence[bold]&#xa0;[bold]4.1
[normal]&#xa0;&#xa0; 
[normal]Leading on from parental responsibility, it is important to recognise that the technical safety features of these sites are integral to the sites themselves.  It does not matter where a user accesses them from, on what device, or through which network, the safety features remain consistent.
[normal]&#xa0;[bold]4.2
[normal]&#xa0;&#xa0; 
[normal]BeatBullying is completely in agreement with the principle of blocking genuinely harmful content such as pornography but could not endorse any system that might deny access to legitimate information, advice and support around sensitive issues due to over-zealous and inadequately nuanced filtering.
[normal] [bold]It would be valuable if categories subject to filtering were broken down into more meaningful neutral, positive and negative sub-groups, such as: ‘Eating disorders
[normal]—
[normal]general information’ (neutral), ‘Eating disorders
[normal]—
[normal]advice and support for prevention or recovery, such as the charity Beat’ (positive) versus ‘Eating disorders
[normal]—
[normal]pro-anorexia (negative)’ and parents could make a separate decision in each of these distinct categories.
[normal]&#xa0;
[normal]4.3
[normal]&#xa0;&#xa0; 
[normal]BeatBullying is in favour of the Government’s ‘pre-select to on’ approach to filtering.  This option has the virtue of simplicity for parents, setting up blocks as the default and requiring a conscious and deliberate opt-in for certain content. However, as explained above, we would welcome more detailed scrutiny of what is or is not acceptable: categories such as ‘violence’ or ‘anorexia / bulimia’ in themselves tell us nothing.
[normal]&#xa0;
[normal]4.4
[normal]&#xa0;&#xa0; 
[normal]Implicit in having certain things ready-blocked is a ‘social norm’ of what is and is not acceptable. The assumption inherent in pre-blocked content is that parents will not want their children to access pornography etc., and the idea is that this acts as a prompt to conform to this expectation. While we believe that the majority of parents are responsible, there is a minority who might lack either the capacity or the will to make informed decisions in this area. That is why we take the view that having automatic blocks on some content, which can be removed by adults if they choose, would be the best option to ensure a balance between guidance and freedom, thereby protecting children more effectively.
[normal]&#xa0;
[normal]4.5
[normal]&#xa0;&#xa0; 
[normal]It is important that in a time where technology has outstripped the capacity of law enforcement, filtering and blocking is not just at the feet of parents; it is imperative that search engines and ISP’s actively challenge themselves to work towards an advancing solution to an on-going problem. In July this year the Prime Minister threatened legislation if internet providers failed to commit to a blacklist of CEOP search engine terms which we support and hope that progress is swift. 
[normal]&#xa0;[bold]4.6
[normal]&#xa0;&#xa0; 
[normal]Since 2008 the UK Council for Child Internet Safety has tried but failed to introduce meaningful self-regulation.  BeatBullying would therefore introduce r
[normal]egulations on internet safety that would:
[normal]&#xa0;
[normal]&#xa0;[bold]5[bold]&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; 
[normal]Preventing abusive or threatening comments on social media[bold]&#xa0;
[normal]5.1
[normal]&#xa0;&#xa0; 
[normal]Our latest survey
[normal] of children and parents 
[normal]found:
[normal]&#xa0;
[normal]&#xa0;
[normal]5.2
[normal]&#xa0;&#xa0; 
[normal]Whilst there are technological advances that allow streams of text to be analysed and flagged up for bullying behaviour, BeatBullying works to educate and empower children and young people to take responsibility for their actions and understand that bullying in any form is unacceptable. 
[normal]&#xa0;
[normal]5.3
[normal]&#xa0;&#xa0; 
[normal]Among primary-school children who participated in our 2012 research
[normal], 6% of those who had experienced cyberbullying had been targeted on a hate site or hate group (often referred to as Trolling), 9% had had embarrassing images circulated and 10% had had a photo edited to make fun of them. There are also qualitative accounts of children this age experiencing death threats and sexual harassment online. Among 11 – 16 year-olds who had been cyberbullied, 6% reported receiving a message or image on the subject of sex which had made them feel uncomfortable or upset. Of those who knew who had sent it, the vast majority (80%) said that it had come from someone around the same age. 
[normal]&#xa0;
[normal]5.4
[normal]&#xa0;&#xa0; 
[normal]This research found that one in 13 secondary-school and one in 10 primary-school-aged children had been subjected to an intensive, relentless campaign or online attack over a period of weeks, months or even years by other children or young people. Many online phenomenon’s such as ‘
[normal]sexting
[normal]’
[normal]—
[normal]sending sexual pictures and messages via mobile phone
[normal]—
[normal]is overwhelmingly peer-to-peer; it is an instance of children and young people victimising each other and unknowingly victimising themselves, by sharing photos that can be used as weapons for bullying or end up in the hands of adult predators. This perfectly illustrates the point that a significant proportion of negative online content is generated by young people themselves. Given this, it is a concern that any discussion of technological blocking and filtering systems in isolation does not take into account the interactive and user-generated nature of some harmful material, which is likely not to come within the scope of a filter anyway. To our knowledge, it is not possible completely to block interactions such as bullying or ‘sexting’, although, as outlined above, there are both technological and human ways of curtailing these and limiting the harm done. 
[normal]Blocks and filters can only block and filter; they cannot educate children about how to deal with the kind of content and behaviour they might encounter online, how to manage their own behaviour responsibly or why certain material is harmful. 
[normal]&#xa0;
[normal]5.5
[normal]&#xa0;&#xa0; 
[normal]That is why BeatBullying has been calling for several years for education programmes focusing on behaviour and addressing issues such as cyberbullying and e-safety, to be introduced into all schools. We support and welcome the proposed changes on e-safety to be introduced in the 2014 national curriculum across all key stages. It is clear that education for safety and good behaviour online needs to begin as early as possible, before cyberbullying even becomes an issue. 
[normal]&#xa0;
[normal]5.6
[normal]&#xa0;&#xa0; 
[normal]Everyone involved with children’s and young people’s use of the internet
[normal]—
[normal]parents, schools, service providers, organisations and children themselves
[normal]—
[normal]needs to be seen as sharing responsibility for online safety.  In April 2013 BeatBullying launched a campaign for better anti-bullying protections called Ayden’s Law
[normal].  This campaign called on the Government to produce a national anti-bullying / cyber bullying strategy which would, for the first time, set out the role of teachers, parents, local authorities, the public, the voluntary &amp; community sector and children and young people themselves in preventing and intervening when bullying and cyber-bullying takes place.  Without the introduction of this strategy, progress in tackling online bullying and other safety threats will always be frustrated by the lack of understanding of roles and responsibilities by those charged with keeping children safe online.
[normal]&#xa0;
[normal]5.7
[normal]&#xa0;&#xa0; 
[normal]A national strategy to tackle cyber-bullying would set out how the voluntary and community sector, parents, schools, LAs and the police would be equipped to (a) protect the children in their care from harm online and (b) educate and equip children about internet safety and responsible digital citizenship so that they understand the issues for themselves. The implementation of this can be greatly facilitated by a solid technical framework of support from business, such as Claire Perry’s work with internet providers to introduce preselected parental controls or the adoption of the measures listed in para 4.6 above.
[normal]5.8
[normal]&#xa0;&#xa0; 
[normal]More than 1,700 cases involving abusive messages sent online or via text message reached English and Welsh courts in 2012. However, c
[normal]yberbullying is not a specific criminal offence in the UK. Some types of harassing or threatening behaviour
[normal]—
[normal]or communications
[normal]—
[normal]could be a criminal offence. These laws were introduced many years before Twitter, Facebook and Ask.FM, and they have failed to keep pace with the demands of modern technology.  
[normal]Unfortunately, serious cases of cyberbullying, which have often resulted in suicide, have dominated our headlines in recent months.  That is why BeatBullying have been calling on the Government to review current legislation and make bullying and cyberbullying a criminal offence so that children and young people have the protection they need and deserve, at the earliest opportunity, to avoid this escalation.  This year we have worked with Tracey Crouch MP to introduce bullying and cyberbullying as a form of anti-social behaviour, which will result in victims and perpetrators benefiting from earlier interventions and support outlined in the current 
[normal]Anti-Social Behaviour, Crime and Policing Act Bill.
[normal] [bold]&#xa0;
[normal]5.9
[normal]&#xa0;&#xa0; 
[normal]For BeatBullying, the approach to online safety must ultimately be about shaping attitudes and changing behaviors as much as it is about teaching techniques for staying safe or for anything else; it is about equipping young people with the inner resources that will keep them safe, and responsible, long-term. Some negative online behaviors such as cyberbullying and sexting are most likely to be a form of child-on-child aggression rather than adult-generated; in order to tackle this successfully, it is crucial to work with perpetrators as well as victims to address the attitudes that underlie the behaviour. 
[normal]&#xa0;
[normal]&#xa0;
[normal]September 2013
[normal]&#xa0;[bold]&#xa0;
[normal] Launched May 2013 with The Sun Newspaper following the tragic death of Ayden Olsen Aged 14
[normal] 
[normal]The Online Behavioural Habits of Young People Today
[normal], which questioned a 1000 8-16-year-olds and 1500 parents from
[normal]&#xa0;
[normal]Parentdish
[normal]&#xa0;
[normal]and BeatBullying, July 2013
[normal] 
[normal]Parental Internet Controls Survey: Children and Young People’s 
[normal](
[normal]2012
[normal])
[normal] 
[normal]The Online Behavioural Habits of Young People Today
[normal], which questioned a 1000 8-16-year-olds and 1500 parents from
[normal]&#xa0;
[normal]Parentdish
[normal]&#xa0;
[normal]and BeatBullying, July 2013
[normal] 
[normal]Virtual Violence II Part II: (2012) BeatBullying
[normal] Launched May 2013 with The Sun Newspaper following the tragic death of Ayden Olsen Aged 14
[normal]