&#xa0;
[normal]Written evidence submitted by [bold]Prof Andy [bold]Phippen[bold] [OLS0068][bold]&#xa0;
[normal]Context[bold]&#xa0;[bold]I have been involved in research around online safety for over 10 years and work very closely with 
[normal]organisations such as the 
[normal]UK Safer Internet Centre and 
[normal]South West Grid for Learning 
[normal]as well as many schools across the country
[normal]. This work, over the years, has encapsulated issues of identity and trust, school policy and practice around online safety, onlin
[normal]e safety problems faced by 
[normal]children
[normal] and young people and how 
[normal]our understanding of these
[normal] have changed over the years, and the impact of new technologies on behaviours. 
[normal]I work with young people from primary age up to higher education. 
[normal] 
[normal]&#xa0;
[normal]In all of my researc
[normal]h a fundamental aspect is being able to discuss these issues 
[normal]at a grass roots level 
[normal]with young people themselves. While we might have additional data collection mechanisms such as survey work, the core of any research project will be sitting with young peo
[normal]ple, usually in groups, talking about the research questions and their thoughts. This is all conducted within a clear ethicial framework working alongside schools to place the young people in a safe, non-judgemental environment where they are free to share
[normal] opinions and reflections without being challenged or confronted. Parental consent is obtained for any young people spoken 
[normal]to,
[normal] they are fully briefed on the research context, and have the right to withdraw from the discussions at any time. 
[normal]While these disc
[normal]ussions can sometimes centre on difficult issues, such as sexting, pornography and 
[normal]gender, I usually find the discussions very open and productive (we don’t ask young people to disclose about their own behaviour, but to ref
[normal]lect on the behaviour of peers). 
[normal]I also work with stakeholders in the online safety area, such as parents, teachers and social care professionals to understand their attitudes and concerns related to online safety and young people. 
[normal]A recent example of this work was a piece of research con
[normal]ducted by the NSPCC/UK Safer Internet Centre around sexting
[normal]. 
[normal] 
[normal]&#xa0;
[normal]In addition to research practice, I am also involved with a lot of schools in an educational context, delivering assemblies and classes related to online issues and associated behaviours. Whi
[normal]le this is not formal research work it further allows the exploration of online safety with young people in a qualitative setting and can elicit interesting and rewarding discussions. 
[normal]&#xa0;
[normal]As well at the work above, all of which is available in the public dom
[normal]ain, I am currently involved in 
[normal]three
[normal] qualitative 
[normal]studies that
[normal], while not yet published, may have relevance to this inquiry. These studies are:
[normal]&#xa0;
[normal]&#xa0;
[normal]In presenting a response to the CMS Committee Inquiry 
[normal]into Online Safety, I 
[normal]w
[normal]ill draw from all of this work to place context around my responses. 
[normal]&#xa0;
[normal]Clearly the online world is something with which the vast majority 
[normal]of young people 
[normal]are engaged and use on a daily basis (indeed, the differentiation between the online and offline is of
[normal]ten something young people do not acknowledge, it is simply “life”). 
[normal]In agreement with the specified i
[normal]nquiry brief, one thing I can observe through many years working in this area is that public understanding of the issues involved in “being” online has 
[normal]im
[normal]proved
[normal] and we have moved on from the traditional threats such as “stranger danger” to a realisation of a complex 
[normal]environment requiring multi-stakeholder 
[normal]input and 
[normal]perspectives. In addition, within the field we have moved away from the belief that young peo
[normal]ple are simply passive participants needing protection 
[normal]toward an awareness of
[normal] fully engaged digital citizens who need to be 
[normal]mindful
[normal] of the impact of their own behaviours on others as well as awareness of the risks involved 
[normal]living in
[normal] the online world.   
[normal]&#xa0;
[normal]D
[normal]igital risk can take many forms, from those well established such as grooming to sexting, cyberbullying/online abuse, accessing inappropriate content and trolling. However, in ensuring protection from harm we must also 
[normal]establish a balance with 
[normal]rights to freedom of expression and access to legitimate content and interaction. 
[normal]&#xa0;
[normal]As someone who has worked in the field for a long time, it is encouraging to see Parliament engaging with these issues in recent time. However, a lot of recent policy discu
[normal]ssion around this topic has focused on a very specific aspect of online life – access to adult content and the measures needed to ensure young people cannot see this. 
[normal]&#xa0;
[normal]More concerning is that this dialogue seems now to have grouped access to clearly illeg
[normal]al content (child abuse images) with access to legal content for 
[normal]adults which is
[normal] inappropriate
[normal] for minors. These are two very separate issues and it is not helpful to be presenting them in the same context – countermeasures to tackle child abuse images are
[normal] clearly set in law and addressed by excellent organisations such at the Internet Watch Foundation. Child abuse images are illegal and no one has the “right” to access them. However, when we are talking about legal content inappropriate for young people it
[normal] is a far more complex debate as we do not want to restrict the rights of the public 
[normal]or ostracise them in some way (for example by suggesting that there is a link between access to legal and illegal content) 
[normal]in order to protect young people. 
[normal] 
[normal]&#xa0;
[normal]This is a very narrow aspect on online safety at large – what about sexting, cyberbullying, trolling, upset by “innocuous” content, education, the right to discuss these issues in school, etc.? 
[normal]It
[normal] is encouraging to see that this inquiry is, at least in par
[normal]t, looking to broaden to Parliamentary debate and to start to ask questions around the wider 
[normal]context
[normal]. 
[normal]This is something that will be explore
[normal]d
[normal] in more detail when addressing the specific points of the inquiry below.
[normal]&#xa0;
[normal]How best to protect mino[bold]rs from accessin[bold]g adult content[bold]There has been much discussion over this point over the last couple of years. The OCC published an excellent, balanced, review of the l
[normal]iterature in this area recently
[normal]. 
[normal]However, I would like to present a slightly different perspective on th
[normal]is matter that has arisen from my discussions with young people. Adult content is certainly nothing 
[normal]new,
[normal] it has been available far longer than it has been accessible online. However, the challenge presented in the online world is both accessibility and the
[normal] type of content 
[normal]one can now download
[normal]. While 25 years ago magazines and perhaps VHS videos provided a level of access to adult content, it was not as strong or diverse at the availability of pornography online. This is something that has been acknowledged 
[normal]by many young people I have spoken to. 
[normal]&#xa0;
[normal]I
[normal] was asked over the summer this year by a 14 year old boy what I thought about people his age looking at this sort of content. This is an interesting question to pose because it both acknowledges that young people 
[normal]of this age are frequent users of pornography (this has been borne out in my discussions with young people of this age, particularly boys) and also challe
[normal]nges the social belief they should not be doing it. My answer was 
[normal]hopefully a pragmatic 
[normal]one – I would 
[normal]rather they didn’t but I wasn’t naïve enough to think they could be prevented from accessing it, so I would rather we focused on providing an environment in schools where they could talk about the possible issues that arise from access to this sort of cont
[normal]ent. 
[normal]&#xa0;
[normal]Protection from access is an interesting concept. How can we protect them from content they wish to access
[normal] (which is certainty something I would observe from talking to boys far more than girls)
[normal]? This, again, was 
[normal]reflected
[normal] in discussions recently wi
[normal]th a very mature group of 14-16 year old boys in a local school – one boy, who was discussing the recent policy discussions around “opt-in” and filtering in the home, made a very clear statement: “You will not 
[normal]prevent teenage
[normal] boys from accessing pornograph
[normal]y”. He did not state this to be rebellious or 
[normal]controversial,
[normal] he was stating it from his observations of his peers. They access and share pornography and have many ways of doing so.
[normal]&#xa0;
[normal]Much of the recent debate has been around filtering
[normal] and it is worth explor
[normal]ing this as a “solution”, which is clearly is not. Software can only ever provide tools to 
[normal]provide some level of support to
[normal] what are, essentially, social issues facilitated by technology. We have worked with filtering in schools for a long time now and whi
[normal]le it is certainly a useful tool to prevent access to inappropriate content in the school setting, it is equally clear that filtering controls have to be set extremely high in order to prevent access to those things the school does not wish their pupils to
[normal] see. 
[normal]&#xa0;
[normal]Therefore, lots of innocuous content will be also be blocked which can lead to frustration for both staff and pupils. This is because filtering is still a pretty blunt tool – 
[normal]in general 
[normal]it looks for keyword and blacklisted sites and prevents access
[normal] as a result. Filtering still struggles with context – the famous Scunthorpe problem being a clear example of this (and some filters wi
[normal]ll still block this). F
[normal]iltering also only blocks the channel on which the technology is installed – in the case of a scho
[normal]ol 
[normal]this channel would be 
[normal]the institutions network. It will not prevent an ambitious young person with a mobile device handed down from their parents from accessing this content. And 
[normal]if 
[normal]an individual’s mobile device has been set up to prevent accessing adul
[normal]t content, they will have a friend whose device hasn’t and they will share content via Bluetooth, MMS, etc. 
[normal]&#xa0;
[normal]One boy I spoke to recently was more candid when I discussed the recent policy directions with him – he said he doesn’t care whether people preven
[normal]t him from accessing indecent images online, he’ll just ask a local girl to send him pictures instead. While this does present a number of issues, notwithstanding a very concerning attitude toward women in general, it does clearly highlight one issue that 
[normal]doesn’t seem to be discussed in the recent debates – online consumption of “professional” pornography is only one source of indecent content for young people. 
[normal]&#xa0;
[normal]Filtering will prevent access for those not wishing to find inappropriate content, and as such 
[normal]does provide some use in this area. 
[normal]If
[normal] we turn our focus to filters in the home it may prevent younger children from stumbling across this sort of content, but will it “protect” 
[normal]a determined teen? Also, if filtering in the home is 
[normal]going to present similar 
[normal]overblocking challenges as those solutions in schools
[normal], how many homes will switch off the filters because they become too frus
[normal]trating to use and because they prevent access to legitimate content?
[normal] Certainly the Open Rights Group
[normal] (I am on the advisory counci
[normal]l for this organization)
[normal] have many examples of adults contacting them because 
[normal]of
[normal] filters that, whether on home computers or mobiles, have prevented access to legitimate sites with no means to unblock them. 
[normal]&#xa0;
[normal]On countless occasions young people have asked m
[normal]e why they have no opportunity to discuss these issues in school. Many are also critical of what 
[normal]learning
[normal] they do have around online issues in either PSHE or sex education. Rather than 
[normal]just 
[normal]trying to prevent young people from accessing these 
[normal]sort
[normal] of things
[normal], which will always be a game of catch up when they are finding new ways of access, should we not be providing an education environment where these issues can be discussed
[normal]? Shouldn’t we be providing
[normal] a means for reflection and challenge on why society feels
[normal] this content is inappropriate for young people and what the impact of 
[normal]access might be?
[normal] Sex 
[normal]education which addresses online issues, inappropriate content, etc. seems to be extremely disjointed and generally delivered by the few specialists we have in this
[normal] area in the UK. I certainly hear very rarely of this sort of lesson being delivered in a school by teachers within the establishment. Yet whenever I have had sessions in schools with both boys and girls around this topic (which can results in very differe
[normal]nt conversations) I have found the young people to be engaged and enthusiastic in their discussions and ask to do more of this sort of thing. 
[normal]&#xa0;
[normal]So the barrier is not the unwillingness of the pupils, but the lack of coordination nationally to permit teacher
[normal]s to address these things in schools. Education in this sort of area requires multi-stakeholder buy in from staff, parents, pupils and policy makers. A lone teacher who believes this is important may subsequently suffer at the hands of 
[normal]senior management, 
[normal]p
[normal]arents or governors who have received no “permission” to address these topics within the curriculum. 
[normal]&#xa0;
[normal]Filtering out extremist material, including images of child abuse and material intended to promote terr[bold]orism or other acts of violence[bold]Much of the discus
[normal]sion above is equally pertinent to this point, filtering cannot be seen as the 
[normal]complete 
[normal]solution. It is good to see acknowledgement that harmful content online is not just pornography 
[normal](indeed, in my discussion
[normal]s,
[normal] young people are far more likely to say they
[normal] have been upset by images of violence or animal abuse than they are by sexual content) 
[normal]but again we need to be clear about 
[normal]the difference between what is legal and what is illegal. If content is illegal, the Internet Watch Foundation (IWF) have a very cle
[normal]ar remit for reporting, investigating and either blocking or moving for prosecution (depending on whether the content is hosted abroad or in the UK). The IWF maintain a blacklist of sites serving illegal content and all 
[normal]ISPs within the UK buy into this
[normal].
[normal] Th
[normal]e key
[normal] challenge for the IWF is awareness of their 
[normal]role
[normal] among the public and this could be something that could be 
[normal]helped
[normal] by UK Government. 
[normal]&#xa0;
[normal]However, when we consider legal, but upsetting, content, we are in more difficult territory if we are looking to fi
[normal]lt
[normal]ering as a solution. Who decides
[normal] what should be filtered? How can we be sure about the meaning and intent behind a search term (for example, if one is searching for extremist materials might use the same search terms as someone conducting research on the
[normal] area)? And is this a sliding scale of upset? I have had many young people tell me how RSPCA adverts have upset them – should we move to block them too? Again, I would rather see a society that, rather than trying, and failing, to prevent access to anythin
[normal]g that 
[normal]might
[normal] upset a young people, provides an environment where
[normal] there are aware upsetting content can come in many different forms and affect individuals in different ways and
[normal] if they are upset, they can talk to someone about it. During my work around sex
[normal]ting I was amazed at how few young people would turn to a te
[normal]acher if they became a victim
[normal]. 
[normal]They
[normal] feared a lack of understanding or a judgmental response. That is a real concern because we 
[normal]cannot
[normal] possibly consider, and filter, 
[normal]all
[normal] content an
[normal]y
[normal] individual youn
[normal]g person might finding upsetting. To consider young people as a single collective is patronising to the diversity 
[normal]and individuality they exhibit and what upsets one may be viewed as humorous or innocuous by another. 
[normal]&#xa0;
[normal]Preventing abusive or threatening comm[bold]ents on social media.[bold]Finally, while it is good to see an Parliamentary committee looking at this issue, because when I talk to young people about online issues cyberbullying (or simply “people being mean”) is by far the most likely response whe
[normal]n I ask what upsets them online, I would, again, take issue with the wording used. Put simply, you will never 
[normal]prevent
[normal] abusive or threatening comments on social media, just 
[normal]as
[normal] you will never prevent nasty comments in the playground, on TV shows such as the X Factor, on the football pitch
[normal] or at PMQs
[normal]. However, far more can be done to provide an environment where young people should know they do not have to put up with this sort o
[normal]f thing and that 
[normal]people can
[normal] help. I should stress, first of all, that it is rare that a young person will talk about “cyberbullying” and the term is unhelpful when trying to address the problems caused by people being abusive online. Online abuse can be de
[normal]scribed in many forms, such as nastiness, people being mean, calling names, ganging up or simply banter and again 
[normal]equitability is difficult to manage in this area – one young person
[normal]’
[normal]s banter will be considered abuse by another. 
[normal]&#xa0;
[normal]However, it is important t
[normal]hat services providers 
[normal]offer
[normal] the means to report abuse, something that is 
[normal]already in place
[normal] by some social media platforms but not others. Young people also need to be aware that they can use these reporting mechanisms to take comments down and also they wi
[normal]ll not get into trouble themselves. The wording of some reporting functions is intimidating and can be overwhelming for young people. 
[normal]&#xa0;
[normal]But, once again, education is the pivotal player in this area – education around 
[normal]what
[normal] is and isn’t acceptable language, 
[normal]the impact of abuse on others, 
[normal]the disconnect
[normal] and perceived anonymity the Internet provides, and the potential 
[normal]il
[normal]legality of some forms of abuse. 
[normal]&#xa0;
[normal]It is also encouraging to see some discussion from the Director of Public Prosecutions and Crown Prosecution
[normal] Service around this 
[normal]issue,
[normal] it is helpful to get some clarification on abusive language. It is also encouraging to see it stated it is rarely in the public interest for minors to be prosecuted for this sort of thing.
[normal]&#xa0;
[normal]I have seen a number of schools adopti
[normal]ng a restorative justice approach to the resolution of online abuse issues and this makes sense – in a lot of cases the perpetrator will not be aware of the impact of their words on the victim and to place them in an environment where they can hear about i
[normal]t is a powerful one. However, it is important the restorative justice is implemented effectively with trained counselors – it is not something that can be done effectively without experienced professionals. 
[normal]&#xa0;
[normal]&#xa0;
[normal]In summary, it is encouraging to see this inqu
[normal]iry exploring some of the broader issues around online safety and not just focus on the headline grabbing ones. However, it is still a concern that a lot of the language focuses on prevention and filtering rather than education and awareness. The Internet 
[normal]is not something that can be “policed” with technology. If we wish to protect young people and help them protect 
[normal]themselves, we can
[normal]not 
[normal]lay
[normal] responsibility 
[normal]solely on 
[normal]service providers and software just as we cannot blame the Royal Mail for delivering an unwa
[normal]nted letter. We need parents to be aware of issues, we need education professionals to be able and allowed to provide an effective environment to both learn about and talk about these issues, and we need policy makers who are awareness of the broad context
[normal] of online safety and the complexities of growing up in the digital age.  
[normal]&#xa0;
[normal]September 2013
[normal]&#xa0;
[normal] 
[normal]http://www.nspcc.org.uk/Inform/resourcesforprofessionals/sexualabuse/sexti
[normal]ng_wda93252.html
[normal] 
[normal]http://www.mdx.ac.uk/Assets/BasicallyporniseverywhereReport.pdf
[normal]