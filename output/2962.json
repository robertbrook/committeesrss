"&#xa0;\nWritten evidence from  the Open Data User Group (ODUG) [OD14]&#xa0;&#xa0;\n&#xa0;\nSummary&#xa0;\n1.1.\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nThe Open Data User Group (ODUG) is an independent advisory body appointed by the Chair of the Group and the \nMinister for the Cabinet Office\n. It receives administrative support from staff in the Cabinet Of\nfice, but speaks independently\n on behalf of the data community\n&#xa0;\n1.2.\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nThis is a collective response from ODUG to the Public Administration Select Committee request for evidence on statistics and open data\n.\n&#xa0;\n1.3.\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nIndividual members of ODUG, or their employing organizations, may make separate responses.\nOur main observations are\n:\n&#xa0;\n2.1\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nThe release of Public Sector Information, which is not restricted on grounds of privacy or security, as Open Data, is the most effective way \nof maximising its utility and allowing the nation to \nachieve\n \nmaximum\n benefit from\n the \ntaxpayer \nfunds used to collect the data originally\n.\n&#xa0;\n2.2\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nIn addition to re-use, which may generate additional economic activity, Open Data contributes to transparency enabling the public to hold the public sector to account\n for the effective delivery of public services. W\nhere \nsuch data\n relates to the quality of public services \nit \ncan often allow the public to exercise informed choice.\n&#xa0;\n2.3\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nMaking information available as Open Data often leads to improvements in quality as errors \nwill\n \nbe noticed and reported by more individuals and organisations\n.\n&#xa0;\n2.4\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nGovernment policy relating to which data should be open, which should be closed\n,\n which should be traded \nand at what prices \nhas been incoherent and has often appeared to be arbitrary\n and lacking in detailed accountability\n.\n&#xa0;\n2.5\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nDespite the agreed policy of a ‘presumption to publish’ t\nhe release of public sector \ninformation as Open D\nata has often been in\nconsistently\n planned \nand is poorly\n regulated. There needs to be clear accountability where public officials \nare\n answerable to a single body or individual who will \nensure\n \nthat they are fulfilling their obligations to release \nOpen Data\n.\n&#xa0;\n2.6\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nAll future systems to collect public sector data for the fulfilment of public services delivery should be \nrequired, from their inception, to build in an \nOpen Data \ndelivery mechanism\n which is publicly accountable and takes data security and privacy issues into consideration\n.\n&#xa0;\nPASC’s questions&#xa0;\n1. Why is open data important?&#xa0;\n1.1\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nInformation has become the key economic resource of the 21\nst\n century. The economic \nefficiency and the \ncompetitiveness of nations will depend on the choices that are made over how data is collected and shared to maximise the opportunities of deriving information from it.\n&#xa0;\n1.2\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nPrivate companies have a clear obligation to use data, in the same way as any other resource, to maximise the return to shareholders.\n&#xa0;\n1.3\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nSome private companies achieve this by \napparently \nmaking the data they collect, create or collate openly available. This is usually not the case as\n, often, users are only permitted\n to view the data,\n not to capture and reuse it. \nMaking the data ‘open’ to view only is a mechanism \nto attract users to view advertising material that is placed\n alongside it, and data reuse is limited\n to prevent the collation of information\n by others.\n&#xa0;\n1.4\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nG\nenuinely Open Data from the private and \nvoluntary \nsectors is rare. Wikipedia and OpenstreetMap.org are notable exceptions\n; \nboth \nare \nnot-for-profit organisations that allow the relatively free re-use of their data.\n&#xa0;\n1.5\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nIn the age of broadband and superfast broadband the internet has become a ubiquitous \nchannel of communication\n. \nOnce initial data hosting costs are covered \nthe marginal cost of sharing data \nis \nclose to zero\n and\n allows the release of Open Data as a public good at a substantially lower cost than previous mechanisms for disseminating data which carried significant costs. It is this technological change that has created the Open Data opportunity.\n&#xa0;\n1.6\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nAround the world many governments are coming to the conclusion that maximising the amount of Open Data available to citizens and businesses is the way to maximise the economic benefit that countries as a whole can derive from that data. This is particularly the case for Public Sector Information (PSI) which has already had to be collected in order to allow government departments or agencies to fulfil their Public Task\ns\n. European regulations on the re-use of PSI strongly encourage the release of as much of it as possible as Open Data (subject to privacy or security constraints) in order to maximise its re-use and the economic activity related to its re-use.\n&#xa0;\n&#xa0;2.1.\n&#xa0; \nGovernment has had \nperiodic \nmajor strategic reviews of the release and charging mechanisms for \npublic sector information, in particular \nstatistical information\n and core reference data\n.\n Perhaps the most significant ones have been\n:\n&#xa0;2.2.\n&#xa0; \nT\nhe \nRayner Review of 1979, which led indirectly to a Tradable Information policy being introduced by the Treasury which lives on in guidelines for charging for government information.\n&#xa0;\n2.3.\n&#xa0; \nTh\ne\n \nRayner R\neview created a situation where vital statistical information, and in particular Census Information was no longer freely available even to Government Departments, but had to be purchased through “Census Agencies”, private sector brokers who paid a licence \nfee for the exclusive right to re-sell government statistical information.\n \nThis led to some government departments claiming that they were no longer able to afford to pay for the information necessary to carry out aspects of their Public Tasks\n.\n&#xa0;\n2.4.\n&#xa0; \n“Crown Copyright in the Information Age” published in 1998. Rather than taking a strateg\nic view of what data should be o\npen and how it should be funded, this review divided agencies into those that were successfully recovering a significant proportion of their costs by trading in information, such as Ordnance Survey\n (OS)\n, and should continue to do so, and those not recovering significant costs which were liberated to release their data without charge, such as \nthe Office for National Statistics\n (ONS)\n.\n \nThe impact of this \nseemingly \npragmatic decision was to create a difficult divide between the trading agencies and the Open Data agencies.\n&#xa0;\n2.5.\n&#xa0; \nAddressing and geospatial data is of particular value \nto \nall aspects of our \nsociety\n. Its pseudo-c\nommercialisation as tradable data underpins much of the complexity found in the public sector information landscape where many publ\nic sector bodies re-purchase \ndata \nfrom one-another in\n \nan overly complex, inefficient system which re-cycles\n public money \nbetween publicly owned entities.\n&#xa0;\n2.6.\n&#xa0; \nFurther complexities in licensing and re-use of public sector information arise from this system particularly where so-called ‘derived-data’ restrictions are put in place by the data holders. For example Ordnance Survey place restrictions on both public sector and private sector organisations re-using \ntheir own data,\n once it has been combined in some way with OS data.\n \n&#xa0;\n2.7.\n&#xa0; \nAs an\n example,\n in\n \npreparing for the 2001 Census\n the ONS found itself unable to afford all the geographical data from the OS which would have been helpful in conducting the Census.\n  \nFollowing the publication of 2001 census results in 2003,\n \nONS found that it was unable to release \nthe census \noutput area boundaries\n (OAs)\n as \nunrestricted \nOpen Data, because of Ordnance Survey’s com\nmercial interests in that data.\n&#xa0;\n2.8.\n&#xa0; \nA consultation on ‘Policy options for geographic information from Ordnance Survey’ in 2009 led to the \ndecision \nto \nrelease some \nOrdnance Survey (OS) \ndata as \nOpen Data\n, and the Public Sector Mapping Agreement (PSMA) which makes OS data available for free to the public sector\n. This\n was a significant change of policy, though it did not appear to be part of an overall strategy\n and excluded the Royal Mail Postcode Address File (PAF)\n. OS negotiated with a nominated “intelligent customer” as to which products should be released as Open Data. These included administrative and statistical boundaries in BoundaryLine and Postcode locations (though not the locations, or the text, of individual addresses). \nThis was a significant step forward\n for the Open Data agenda\n, but \ndid not deliver a\n coherent Open Data strategy.\n&#xa0;\n2.9.\n&#xa0; \nThe \nCabinet Office Open Data White paper and the subsequent Shakespeare Review both make cogent and compelling cases for Open Data. However neither can be regarded as a strategy and, while they have led to the release of over 10,000 government data sets, these have not been released or prioritised according to any discernible strategic framework. Nor is there any regulatory mechanism to ensure \nongoing \npublication, release or change update strategies for \nthe \ndata sets that have been released.\n&#xa0;\n2.10.\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nIn order for the country to gain the maximum utility and economic advantage from Open Data a more strategic response is needed. There needs to be a single, permanent, locus in government for the regulation of Open Data release and for the dissemination of a coherent strategy which will outline: \n(i) \nwhat should be released; \n(ii) \nhow it should be released; \n(iii) \nhow frequently dynamic data sets \nshould \nbe updated or whether, by simply exposing dynamic data sets, users \nshould\n \ntrack change\ns\n themselves; \n(iv) \nwhat metadata standards should be used \n(data.gov.uk delivers a quasi standard and the recent National Information Infrastructure guidelines for departments are an additional step) \nand\n; (v) \n what skills and funding are required to ensure that the Open Data strategy is sustainable.\n \n&#xa0;\n2.11.\n&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0;&#xa0; \nIn the short term the Cabinet Office has taken on this role enthusiastically\n and is achieving some good results\n. \nHowever the \noverall \nremit is spread across many public sector bodies including the\n Office for Public Sector Information\n, the \nInformation Commissioner’s Office\n,\n The Department for Business \nInnovation\n and Skills (BIS)\n, \nd\nata holders within individual departments\n and their agencies\n, Local \nAuthorities\n and other public \ns\nector \nd\nata holder\ns\n. These bodies do not work effectively together which we suggest is as a result of \n(a) the historic complexity of the legislative and executive landscape; and (b) \na lack of overall strategy\n and priorities for Open Data\n and \nO\npen \nD\nata standards\n.\n&#xa0;right ones?&#xa0;3.1\n&#xa0; \nT\nhe Government’s stated aims for the release of \nO\npen \nD\nata and the stated key outcomes of the \nO\npen Data Strategy are entirely appropriate and laudable. We support them strongly.\n&#xa0;3.2\n&#xa0; \nHowever we cannot be sure that there is a \ncoherent \ncommitment to the Open Data Strategy from all government departments. \nThe government\n appears to be resolutely focussed on relatively small revenue streams arising from some of the Trading Funds and a short term focus on raising one-off revenues through the privatisation of public assets, which include fundamental datasets. As a result \nboth parts of BIS and the Shareholder Executive \nare pushing forward short-term policy decisions which undermine the fundamentals of the\n Open Data Strategy.\n&#xa0;3.3\n&#xa0; \nWhile the release of individual data sets is valuable, some data is essential to make other data sets meaningful. This is sometimes referred to as “Core Reference Data”, items of data which will be used across many data sets \nas identifiers to show what a record relates to\n. This data\n need\ns\n to be \nmaintained and disseminated from a single source. Examples are: addresses with postcodes\n and geo\n-\ncoordinates\n; geographical codes for statistical or administrative areas; company registration numbers; VAT numbers; codes or standardised names for health or \neducational establishments\n; NHS numbers; Social Security numbers\n, classifications for public administrations and their services\n.\n&#xa0;3.4\n&#xa0; \nSome p\nersonal identifiers are contentious and should not be released as Open Data except as part of a system that anonymises records and preserves and protects the privacy of individuals. Others are, or should be, matters of public record, these include Company Registration Numbers, VAT registrations\n.\n&#xa0;3.5\n&#xa0; \nThe decision by BIS to allow Royal Mail to take the Postcode Address File (PAF) into private ownership as a commercial data set, and for Ordnance Survey to participate in the creation of GeoPlace LLP as a trading Value Added Reseller of PAF which intends to commercially exploit geographically referenced addresses appears to fly in the face of any Government commitment to Open Data.\n&#xa0;3.6\n&#xa0; \nThe Office for National Statistics has consistently explained how essential a single National Address Register is for a wide range of statistical purposes from taking a reliable Census, through Census alternatives to the sampling and geographical aggregation of many other surveys.\n&#xa0;3.7\n&#xa0; \nFor users of statistics it is very important to know what set of addresses ar\ne\n included in each statistical area so that other data can be matched reliably to data from ONS, or data can be submitted to ONS reliably. It is difficult to understand how this can be accomplished effectively if a National Address \nR\negister is not available as Open Data.\n&#xa0;&#xa0;4.1.\n&#xa0; \nThe availability of government datasets as part of the National Information Infrastructure, including a single underlying platform of Core Reference Data needs to be agreed, delivered and maintained.\n&#xa0;4.2.\n&#xa0; \nGovernment analysts and statisticians should make the widest possible use of this data, to avoid the inefficiency associated with multiple dataset-capture and maintenance of essentially identical sets of public sector information.\n&#xa0;\n4.3.\n&#xa0; \nThe use of single data repositories will enable im\nproved like-for-like comparison and\n peer review in the generation of management information and statistics. Open \nD\nata allows improved levels of analysis and innovation, and will also increase the quality of the underlying data (the more users of a given dataset the higher the number of issues which will be detected and can be rectified).\n&#xa0;&#xa0;\n&#xa0;\n&#xa0;\n&#xa0;5.1.\n&#xa0; \nBy enforcing the current presumption to publish a\nnd\n making sure all new data collection and IT contracts: (i) do not duplicate what is already collected by others; (ii) are designed with the release of Open Data as an upfront requirement. This should apply to all public bodies i.e. Central and Local Government.\n&#xa0;5.2.\n&#xa0; \nSustainable funding \nis essential to ensure that public sector information is made available, and continues to be available as Open Data. This can be achieved by ensuring that the cost of exposing data on an open platform is included in the initial cost of any project requiring data (this is generally likely to be a marginal overhead on the basic data collection cost\ns).\n&#xa0;\n5.3.\n&#xa0; \nWhere data is generated as a result of statutory registration, such as: Land Registration, registering to vote, being registered to pay Council Tax or Business Rates, registering a planning application or building regulations consent etc. the cost of registration should include an element used to make the data collected openly available.\n&#xa0;\n5.4.\n&#xa0; \nA principle of charging those who cause \nO\npen \nD\nata to change, rather than those who seek to use it, should be adopted as government policy.\n \nCitizens \nalready pay to register births, deaths, marriages, cars, companies, land, planning applications, building permits and many other transactions. Each of these cause official data to change. A fee charged to a person registering, or causing, a change in an official record, should include an element that pays for that data to b\ne included and disseminated as Open D\nata. This is a much\n more efficient way of funding Open D\nata than closing the data and charging for \nits \nuse\n. It requires fewer tra\nnsactions, the sum\ns\n involved \nare a s\nmall percentage of \nthe fees being paid \nand collected\n anyway and the amount\n collected is directly proportional to the update effort so there is no need to speculate how many times data will be used to set a price. This is a fair, efficien\nt and effective way of funding Open D\nata generated as part of a public task.\n&#xa0;&#xa0;6.1\n&#xa0; \n(a) The default requirement for CSV format is adequate in the first instance. Moves to deliver Linked Data formats are welcome, but not essential. The provision of APIs is useful in some use cases, but it does not constitute a proper Open Data solution to deliver a service (ie: pre-analysed or aggregated results) without allowing for the bulk download of the underlying data.\n&#xa0;6.2\n&#xa0; \n(a) \nWhile releasing data in a useful format is helpful and desirable, the minimum requirement should be that data is first released in the format used to deliver the public task for which it was collected. This minimises delay and cost in data release and it is likely that the Open Data community, or value adding re-processors will quickly adapt the data into more usable formats\n. This is the “Raw data now!” principle proposed by Sir Tim Berners Lee, which states that the release of data should be the prime requirement, while improving it to make it more usable is secondary.\n&#xa0;6.3\n&#xa0; \n(a) Where possible data should make use of existing standards and reference common vocabularies to enable the comparison and combination of data, therefore enhancing its reuse. \nOpen Data should comply with the Open Data Certificate \nhttps://certificates.theodi.org/\n.\n&#xa0;6.4\n&#xa0; \n(b) \nAt a minimum m\netadata concerning the available data formats, size of dataset, provenance (data owner),\n \nlatest update (date), frequency of release, data holder (contact details) \nand reference to any common vocabularies \nshould be provided. \n&#xa0;6.5\n&#xa0; \n(b) \nA number of more complete metadata standa\nrds such as Dubli\nn Core and UK Gemini exist and are useful. However the requirement to provide complete metadata to these standards is often a barrier to Open Data release. It is for this reason that we suggest that a very simple metadata record should be treated as essential, while full standard metadata records are regarded as nice to have and can be added after data release.\n&#xa0;6.6\n&#xa0; \n(c) Society\n will use the data. It should be freely \nusable by anyone; public sector\n, \nvoluntary and not-for-profit sectors, \nprivate sector, researchers\n and \nindividual citizens.\n&#xa0;&#xa0;7.1.\n&#xa0; \ndata.gov.uk has been successful in providing a \nfocal point for Open Data and a \nmechanism for the release of datasets which are not currently traded.\n It has been successful in starting to change attitudes and behaviours in the public sector about the rationale for and opportunities to release public sector information as Open Data.\n \nHowever, the main focus is on meeting central government departments’ information publishing needs. data.gov.uk needs to consider the data publishing requirements of the wider public sector, including local government and other public bodies. \nIt is too early to say how widely this data is used, but the provision of a simple mechanism and a single location for data release \nand to locate available datasets is essential.\n \n&#xa0;7.2.\n&#xa0; \nHowever th\ne availability of\n \nthis Open Data \nhas brought to the fore the issue of Tradable Public \nSector \nInformation which is not only unavail\nable as Open Data, but \nif \ncom\nbined with\n, or used in the process of generating, other data sets prevents their \nonward \nrelease in a useful form\n, thereby breaking the \nOpen Data \nmodel.\n \n&#xa0;&#xa0;8.1.\n&#xa0; \nBy definition “Core \nR\neference Data” sets are the most important, these are data sets that provide the identifiers needed to generate \nand combine \nother data sets \nto release value. Core Reference Data \ngenerally identify places, institutions and individuals. Unfortunately the term \nCore Reference Data \nis sometimes used loosely to describe the data sets that individual departments believe are most important \nto their operation, \nrather than \nthe \ndata sets that contain\n true\n “reference” \nor connectivity \ndata.\n&#xa0;8.2.\n&#xa0; \nThe single most frequently cited example of a core reference data set is a National Address Register. \nPast d\necisions concerning the Postcode Address File and the publicly owned GeoPlace LLP company owned by Ordnance Survey and the Local Government Association have undermined, for the time being, the prospect of an Open National \nA\nddress \nR\negister that many are calling for\n as essential to society and to delivering economic value from other Open Data.\n&#xa0;8.3.\n&#xa0; \nAn excellent example of a data set which has been made open after more than a decade of resistance from Royal Mail and Ordnance Survey is the ONS Postcode Directory, an open dataset which gives the administrative and statistical area codes for every postcode current and past. This data set allows organi\ns\nations to create statistical information which can be compared to statistics from ONS, increasing the value of both. Previously this was an expensive data set because of the requirements of the GridLink agreement between Ordnance Survey, Royal Mail and ONS\n which was\n a serious constraint\n.\n&#xa0;8.4.\n&#xa0; \nImportant \nareas where the release of Open Data has made \nthe \nmost progress an\nd delivered tangible results to-\ndate are in \nCompanies House and Land Registry data\n, \nand \neducation, health\n and \ntransport\n datasets.\n&#xa0;&#xa0;\n9.1.\n&#xa0; \nThe Cabinet Office has \nrequired departments to set out \nO\npen \nD\nata \nS\ntrategies which are helpful to set out goals and milestones for the release of Open Data. Over 10,000 datasets are now available on data.go.uk. These are positive results. \nHowever, \nthe mechanisms available to hold\n departments and other public sector bodies to account\n are weak, hampered by a disparate legislative framework with responsibilities spread across multiple bodies and \nthe pace of delivery is relatively slow\n. T\nhere has been little focus \nover the years i\nn \nsetting out an\n overall strategy\n for the Open Data agenda\n, as exemplified in the recent Shakespeare Review. Th\ne programme also lacks any substantial economic analysis to determine which\n datasets \nhave the potential to\n deliver the \ngreatest value to the economy. If a wider strategic approach \nhad \nbeen taken earlier in the programme there would be more robust evidence available to underpin the current debate that core reference data should be made more widely available as Open Data and should not be allowed to pass into private ownership.\n&#xa0;9.2.\n&#xa0; \nOfficials also struggle to engage with the wider community and businesses. Setting up the Open Data User Group (ODUG), as an independent voice\n for the \ndata \ncommunity\n, has \nproven to be \na positive step in bridging the gap between Whitehall and the ‘real-world’. T\nhe data request mechanism ODUG has set up on data.gov.\nuk \nis a \ndemand led approach \nwhich \nallow\ns\n the data community to evidence the main barriers\n to the use of public datasets, and to highlight the datasets which will deliver the greatest value if released as Open Data\n. This has enabled ODUG to produce business cases and evidence the need to prioritise certain datasets deemed \nto be\n \nof \nmost value to the data community. \nIt\n is essential that \ndata.gov.uk \ncontinues to \ncollect and \ncreate detailed evidence with the new presumption to publish agenda. \n&#xa0;\n9.3.\n&#xa0; \nAnother very positive step, \nf\nollowing the Shakespeare Review, is the proposal for the National Information Infrastructure (NII) \nrequiring Departments to create dataset inventories and to monitor the release of datasets from those inventories\n. However the initial basis for the\nse\n inventories is rather ad-hoc and it is \ndifficult to judge what is missing from those directories and for what reason.\n Also, the inventories do not include public sector dataset\ns\n collated and held by local authorities, many of which are of high importance and economic value – such as the National Street Gazetteer, nor do they identify datasets which span the requirements of multiple departments\n and public sector organisations\n, where significant efficiencies would be derived by cross-public sector organisation working.\n&#xa0;\n9.4.\n&#xa0; \nIt is not helpful that agreement has not been reached on opening up some of the \nimportant datasets\n (in particular addressing and geospatial data) which are fundamental as an underlying platform of Core Reference Data for the National Information Infrastructure. These datasets are essentially (re-)\npurchased\n from the data holders\n exclusively for the Public Sector\n, including\n products made available under the Public Sector Mapping Agreement\n (PSMA)\n to a restricted set of \np\nublic \nb\nodies, and the proposed Public Sector Licence for the Postcode Address File\n (PAF). In both these cases public funds are used to re-purchase data which was originally funded from the public purse for the delivery of a public task\n.\n \nSuch agreements remove \nthe \npressure to open the relevant data sets \nmore widely for maximum economic benefit. They also leave\n many \npublicly funded and\n/or\n publicly regulated \nbodies\n, such as h\nousing \na\nssociations, the utilities\n and\n charities unable to justify the \nadditional \nexpenditure necessary to use \nessential public sector information which has already been paid for twice by the taxpayer, but whose access is restricted.\n&#xa0;\n&#xa0;\n&#xa0;\nSeptember 2013\n&#xa0;\n9\n&#xa0;\n \nThe OA is the lowest geographical level at which census estimates are provided.\n \nhttp://webarchive.nationalarchives.gov.uk/20120919132719/http://www.communities.gov.uk/publications/corporate/ordnancesurveyconsultation\n"